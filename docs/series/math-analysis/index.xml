<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Math Analysis on My Notes</title>
    <link>http://localhost:1313/series/math-analysis/</link>
    <description>Recent content in Math Analysis on My Notes</description>
    <generator>Hugo -- 0.138.0</generator>
    <language>en</language>
    <lastBuildDate>Tue, 13 Apr 2021 10:52:59 +0200</lastBuildDate>
    <atom:link href="http://localhost:1313/series/math-analysis/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Mathematical Analysis | 13 Fourier Series</title>
      <link>http://localhost:1313/posts/analysis_1/math_analysis_13/</link>
      <pubDate>Tue, 13 Apr 2021 10:52:59 +0200</pubDate>
      <guid>http://localhost:1313/posts/analysis_1/math_analysis_13/</guid>
      <description>&lt;h2 id=&#34;1-fourier-series&#34;&gt;1. Fourier Series&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;Definition 1 (&lt;strong&gt;Trigonometric polynomial&lt;/strong&gt;)&lt;/dt&gt;
&lt;dd&gt;A &lt;code&gt;Trigonometric polynomial&lt;/code&gt; is a finite sum of the form
$$ 
 f(x) = a_0 + \sum_{n=1}^N (a_n \cos nx  + b_n \sin nx),
$$
where $a_i,b_i$ are complex numbers.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;It can be written in the form
&lt;/p&gt;
$$ 
\begin{equation}
f(x) = \sum_{n=-N}^N c_n e^{inx},
\end{equation}
$$&lt;p&gt;
which is more convenient for most purposes. It is clear that every Trigonometric polynomial has period $2\pi$. Notice that
&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mathematical Analysis | 12 Power Series</title>
      <link>http://localhost:1313/posts/analysis_1/math_analysis_12/</link>
      <pubDate>Mon, 12 Apr 2021 10:52:59 +0200</pubDate>
      <guid>http://localhost:1313/posts/analysis_1/math_analysis_12/</guid>
      <description>&lt;p&gt;In this Chapter we shall the power series formed by the sequence of power functions $\{c_n (x-x_0)^n\}$, i.e. of the form
&lt;/p&gt;
$$ 
 \sum_{n=0}^\infty c_n (x-x_0)^n. \tag{1}
$$&lt;p&gt;
W.l.o.g. we shall focus on the case where $x_0 = 0$, i.e.
&lt;/p&gt;
$$ 
   \sum_{n=0}^\infty c_n x^n. \tag{2}
$$&lt;h2 id=&#34;1-power-series&#34;&gt;1. Power Series&lt;/h2&gt;
&lt;p&gt;First, we study the convergence of series (2).&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Lemma 1&lt;/dt&gt;
&lt;dd&gt;Suppose the series (2) converges for $|x|&lt; R$, then it is absolutely convergent on every  $[-R+\epsilon, R-\epsilon]$.&lt;/dd&gt;
&lt;dt&gt;proof&lt;/dt&gt;
&lt;dd&gt;Let $a_n = |c_n x^n|$, which goes to zero and is bounded. We have $\lim\sup_{n\to\infty}\sqrt[n]{a_n} = 0 &lt;1$. By root test we complete the proof.
$\Box$&lt;/dd&gt;
&lt;dt&gt;Theorem 2&lt;/dt&gt;
&lt;dd&gt;Suppose the series (2) converges for $|x|&lt; R$, and define
$$ 
 f(x) =   \sum_{n=0}^\infty c_n x^n, \quad (|x|&lt; R). \tag{3}
$$
Then (2) converges uniformly on every $[-R+\epsilon, R-\epsilon]$. The function $f$ is continuous and differentiable in $(-R,R)$, and
$$ 
 f&#39;(x) = \sum_{n=1}^\infty n c_n x^{n-1}  , \quad (|x|&lt; R). \tag{4}
$$&lt;/dd&gt;
&lt;dt&gt;proof&lt;/dt&gt;
&lt;dd&gt;For $|x|&lt; R-\epsilon$, we have
$$ 
 |c_n x^n|\leq |c_n (R-\epsilon)^n|
$$
and since $\sum c_n (R-\epsilon)^n$ converges absolutely by Lemma 1, the series (2) converges uniformly on $[-R+\epsilon, R-\epsilon]$.
Next, we have $\lim\sup_{n\to\infty} \sqrt[n]{n|c_n|} = \lim\sup_{n\to\infty} \sqrt[n]{|c_n|}$ since $\sqrt[n]{n} = 1$, which implies that $f$ and $f&#39;$ have the same interval of convergence. As (4) is also a power series, it converges uniformly in $[-R+\epsilon, R-\epsilon]$. We can apply Theorem 11.10 (Differentiation) and obtain the assertion (4).
Continuity of $f$ follows from the existence of $f&#39;$.
$\Box$&lt;/dd&gt;
&lt;dt&gt;Theorem 3&lt;/dt&gt;
&lt;dd&gt;Suppose $\sum c_n$ converges, Put
$$ 
 f(x) =   \sum_{n=0}^\infty c_n x^n, \quad (|x|&lt; 1).
$$
Then
$$ 
 \lim_{x\to 1_-} f(x) = \sum_{n=0}^\infty c_n.
$$&lt;/dd&gt;
&lt;dt&gt;proof&lt;/dt&gt;
&lt;dd&gt;Let $f_n(x) = \sum_{j=0}^n c_j x^j$. $f_n \to f$ at $x=1$, so $f_n\to f$ uniformly on $[0,1]$. Since $f_n$ are continuous, then $f$ is continuous on $[0,1]$ (left continuous at $x = 1$).
$\Box$&lt;/dd&gt;
&lt;/dl&gt;
&lt;!-- Let $s_n = \sum_{j=0}^n c_j$. Then 
$$ 
   \sum_{n=0}^m c_n x^n = \sum_{n=0}^m (s_n - s_{n-1}) x^n = (1-x)\sum_{n=0}^m s_n x^n + s_m x^m.
$$
For $|x|&lt;1$, we let $m\to\infty$ and obtain
$$ 
 f(x) = (1-x)  \sum_{n=0}^\infty s_n x^n.
$$
suppose $\lim_{n\to\infty} s_n= s$. Let $\epsilon&gt;0$ and choose $N$ so that $n&gt;N$ implies
$$ 
 |s_n - s|&lt;\epsilon/2.  
$$
Since $(1-x)  \sum_{n=0}^\infty  x^n = 1 , |x|&lt;1$, we obtain
$$ 
 |f(x) - s| = |(1-x)  \sum_{n=0}^\infty (s_n -s) x^n|\leq |1-x|  
$$ --&gt;
&lt;h2 id=&#34;2-power-series-expansion&#34;&gt;2. Power Series Expansion&lt;/h2&gt;
&lt;p&gt;If (1) converges for $|x-x_0|&lt; R$, and a function $f$ can be represented as $f(x) = \sum_{n=0}^\infty c_n (x-x_0)^n$, then we say $f$ is &lt;code&gt;expanded in a power series&lt;/code&gt;  about the point $x=x_0$.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mathematical Analysis | 11 Sequences and Series of Functions</title>
      <link>http://localhost:1313/posts/analysis_1/math_analysis_11/</link>
      <pubDate>Sun, 11 Apr 2021 10:52:59 +0200</pubDate>
      <guid>http://localhost:1313/posts/analysis_1/math_analysis_11/</guid>
      <description>&lt;p&gt;We have studied how to define a number by convergent sequences or series. In this chapter we discuss how to define a function by a sequence or series of functions, and study the properties of this function.&lt;/p&gt;
&lt;h2 id=&#34;1-uniform-convergence&#34;&gt;1. Uniform Convergence&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;Definition 1 (&lt;strong&gt;Pointwise convergence&lt;/strong&gt;)&lt;/dt&gt;
&lt;dd&gt;Suppose $\{f_n\}$ be a sequence of functions defined on a set $E$, and suppose that the sequence of numbers $\{f_n(x)\}$ converges for every $x\in E$. We can define a function $f$ by
$$ 
 f(x) = \lim_{n\to\infty} f_n(x).  \tag{1}
$$
We say that $\{f_n\}$ &lt;code&gt;converges pointwise&lt;/code&gt; to $f$ on $E$. Similarly, if $\sum f_n (x)$ converges for every $x\in E$, we can define $f$ by
$$ 
 f(x) = \sum_{n=1}^\infty f_n(x).  \tag{2}
$$&lt;/dd&gt;
&lt;dt&gt;Definition 2 (&lt;strong&gt;Uniform convergence&lt;/strong&gt;)&lt;/dt&gt;
&lt;dd&gt;We say that a sequence of functions $\{f_n\}$ &lt;code&gt;converges uniformly&lt;/code&gt; to a function $f$ on $E$ if for every $\epsilon&gt;0$ there exists an integer $N$ s.t. $n\geq N$ implies
$$ 
 |f_n(x) - f(x)|&lt;\epsilon \tag{3}
$$
for all $x\in E$.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;It is clear that every uniformly convergent sequence is pointwise convergent.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mathematical Analysis | 10 Numerical Series</title>
      <link>http://localhost:1313/posts/analysis_1/math_analysis_10/</link>
      <pubDate>Sat, 10 Apr 2021 10:52:59 +0200</pubDate>
      <guid>http://localhost:1313/posts/analysis_1/math_analysis_10/</guid>
      <description>&lt;h2 id=&#34;1-convergence&#34;&gt;1. Convergence&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;Definition 1 (Series)&lt;/dt&gt;
&lt;dd&gt;Given a sequence $\{a_n\}$, we define a sequence $\{s_n\}$ by
$$ 
 s_n = \sum_{i=1}^n a_i.
$$
We call $\sum_{i=1}^\infty a_i$ an &lt;code&gt;infinite series&lt;/code&gt; or just a &lt;code&gt;series&lt;/code&gt;. The numbers $s_n$ are called the &lt;code&gt;partial sums&lt;/code&gt; of the series.&lt;/dd&gt;
&lt;dt&gt;Definition 2 (Convergence of series)&lt;/dt&gt;
&lt;dd&gt;If the sequence $\{s_n\}$ converges to $s$, we say that the series converges, and write $\sum_{n=1}^\infty a_n = s$. If $\{s_n\}$ diverges, the series is said to be diverge.&lt;/dd&gt;
&lt;dt&gt;Theorem 3 (Cauchy criterion)&lt;/dt&gt;
&lt;dd&gt;$\sum a_n$ converges iff for any $\epsilon&gt;0$, there exists an integer $N$ s.t.
$$ 
 |\sum_{k=n}^m a_k|&lt; \epsilon
$$
if $m\geq n\geq N$.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;In other words, if $\sum a_n$ converges, then $\lim_{n\to\infty} a_n = 0$.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mathematical Analysis | 9 Riemann Integrals</title>
      <link>http://localhost:1313/posts/analysis_1/math_analysis_9/</link>
      <pubDate>Fri, 09 Apr 2021 10:52:59 +0200</pubDate>
      <guid>http://localhost:1313/posts/analysis_1/math_analysis_9/</guid>
      <description>&lt;h2 id=&#34;1-definitions&#34;&gt;1. Definitions&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;Definition 1 (&lt;strong&gt;Partition&lt;/strong&gt;)&lt;/dt&gt;
&lt;dd&gt;Let $[a,b]$ be a given interval, by a &lt;code&gt;partition&lt;/code&gt; $T$ of $[a,b]$, we mean a finite set of points $x_0,x_1,...,x_n$, where
$$ 
 a = x_0\leq x_1\leq \cdots\leq x_n = b
$$
We write $\Delta x_i = x_i  - x_{i-1}$, and denote $|T| = \max_i \Delta x_i$ as the &lt;code&gt;mesh&lt;/code&gt; of the partition $T$.&lt;/dd&gt;
&lt;dt&gt;Definition 2 (&lt;strong&gt;Riemann sum&lt;/strong&gt;)&lt;/dt&gt;
&lt;dd&gt;Let $f$ be a given function defined on $[a,b]$, and $T$ be a partition of $[a,b]$. For any points $x_{i-1}\leq\xi\leq x_i$, $i=1,2,...,n$, the summation
$$ 
 \sum_{i=1}^n f(\xi_i)\Delta x_i,
$$
is called the &lt;code&gt;Riemaan sum&lt;/code&gt; of $f$ on $[a,b]$.&lt;/dd&gt;
&lt;dt&gt;Definition 3 (&lt;strong&gt;Riemann integrable&lt;/strong&gt;)&lt;/dt&gt;
&lt;dd&gt;Let $f$ be a given function defined on $[a,b]$, and $J$ be a fixed number. If for any $\epsilon&gt;0$, there exists $\delta&gt;0$, s.t. for every partition $T$ of $[a,b]$ with $|T|&lt;\delta$ and for any choice of $\{\xi_i\}$ we have
$$ 
 |\sum_{i=1}^n f(\xi_i)\Delta x_i - J|  &lt;\epsilon,\tag{1}
$$
we say that the function $f$ is &lt;code&gt;Riemann integrable&lt;/code&gt; on the interval $[a,b]$, we write $f\in\mathcal{R}$ and we denote the $J$ by $J = \int_a^b f(x) dx$.&lt;/dd&gt;
&lt;dt&gt;Definition 4 (Stieltjes integral)&lt;/dt&gt;
&lt;dd&gt;Let $\alpha$ be an increasing and bounded function on $[a,b]$, $f:[a,b]\to \mathbb{R}$. For each partition $T$ of $[a,b]$, we write $\Delta \alpha_i = \alpha(x_i) - \alpha(x_{i-1})$. If for any $\epsilon&gt;0$, there exists $\delta&gt;0$, s.t. for every partition $T$ of $[a,b]$ with $|T|&lt;\delta$ and for any choice of $\{\xi_i\}$ we have
$$ 
 |\sum_{i=1}^n f(\xi_i)\Delta \alpha_i - J|  &lt;\epsilon,\tag{2}
$$
we say that the function $f$ is &lt;code&gt;Stieltjes integrable&lt;/code&gt; w.r.t. $\alpha$ on the interval $[a,b]$, and write $f\in \mathcal{R}(\alpha)$, denoted by $J = \int_a^b f(x) d\alpha(x)$.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;By taking $\alpha(x) = x$, the Riemann integral can be viewed as a special case of the Stieltjes integral.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mathematical Analysis | 8 Indefinite Integrals</title>
      <link>http://localhost:1313/posts/analysis_1/math_analysis_8/</link>
      <pubDate>Thu, 08 Apr 2021 10:52:59 +0200</pubDate>
      <guid>http://localhost:1313/posts/analysis_1/math_analysis_8/</guid>
      <description>&lt;h2 id=&#34;1-definitions&#34;&gt;1. Definitions&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;Definition 1 (&lt;strong&gt;Primary function&lt;/strong&gt;)&lt;/dt&gt;
&lt;dd&gt;Let $f$ and $F$ be functions defined on $I$. If $F&#39;(x) = f(x)$ for every $x\in I$, we say that $F$ is the &lt;code&gt;primary function&lt;/code&gt; of $f$ on $I$.&lt;/dd&gt;
&lt;dt&gt;Theorem 2 (&lt;strong&gt;Existence&lt;/strong&gt;)&lt;/dt&gt;
&lt;dd&gt;If $f$ is continuous on $I$, then $f$ possesses a primary function $F$ on $I$.&lt;/dd&gt;
&lt;dt&gt;Definition 3 (&lt;strong&gt;Indefinite integral&lt;/strong&gt;)&lt;/dt&gt;
&lt;dd&gt;The set of all primary functions of $f$ on $I$ is called the &lt;code&gt;indefinite integral&lt;/code&gt; of $f$ on $I$, denoted by $\int f(x) dx= F(x) + C$.&lt;/dd&gt;
&lt;/dl&gt;
&lt;h2 id=&#34;2-change-of-variable-and-integration-by-parts&#34;&gt;2. Change of Variable and Integration by Parts&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;Theorem 4 (&lt;strong&gt;Change of variable&lt;/strong&gt;)&lt;/dt&gt;
&lt;dd&gt;Let $f(x)$ defined on $I$, $\phi(t)$ differentiable on $J$ and $\phi(J)\subset I$.&lt;/dd&gt;
&lt;/dl&gt;
&lt;ol&gt;
&lt;li&gt;If the indefinite integral $\int f(x) dx = F(x) + C$ exists, then the indefinite integral $\int f(\phi(t))\phi&#39;(t) dt$ exists too, and $\int f(\phi(t))\phi&#39;(t) dt = F(\phi(t))+C$&lt;/li&gt;
&lt;li&gt;If the function $x = \phi(t)$ has inverse function $t=\phi^{-1}(x)$,and $\int f(x) dx = F(x) + C$ exists, then then the indefinite integral $\int f(\phi(t))\phi&#39;(t) dt = G(t) + C$ exists too, and $\int f(x) dx =G(\phi^{-1}(x)) + C$.&lt;/li&gt;
&lt;/ol&gt;
&lt;dl&gt;
&lt;dt&gt;Theorem 5 (&lt;strong&gt;Integration by Parts&lt;/strong&gt;)&lt;/dt&gt;
&lt;dd&gt;If $u(x)$ and $v(x)$ are differentiable, and $\int v(x)u&#39;(x) dx$ exists, then $\int v&#39;(x) u(x) dx$ exists too, and $\int v&#39;(x) u(x) dx = v(x)u(x) - \int v(x) u&#39;(x) dx$.&lt;/dd&gt;
&lt;dt&gt;proof&lt;/dt&gt;
&lt;dd&gt;$[u(x)v(x)]&#39; = u&#39;(x)v(x) + v&#39;(x)u(x)$.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;$\Box$&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mathematical Analysis | 7 Completeness of the Real Numbers</title>
      <link>http://localhost:1313/posts/analysis_1/math_analysis_7/</link>
      <pubDate>Wed, 07 Apr 2021 10:52:59 +0200</pubDate>
      <guid>http://localhost:1313/posts/analysis_1/math_analysis_7/</guid>
      <description>&lt;h2 id=&#34;1-nested-intervals-theorem&#34;&gt;1. Nested Intervals Theorem&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;Definition 1 (&lt;strong&gt;Nested intervals&lt;/strong&gt;)&lt;/dt&gt;
&lt;dd&gt;A sequence of closed intervals $\{[a_n,b_n]\}$ is called a sequence of &lt;code&gt;nested closed intervals&lt;/code&gt; if&lt;/dd&gt;
&lt;/dl&gt;
&lt;ol&gt;
&lt;li&gt;$[a_{n+1}, b_{n+1}]\subset [a_n, b_n]$,&lt;/li&gt;
&lt;li&gt;$\lim_{n\to\infty}(b_n - a_n) = 0$.&lt;/li&gt;
&lt;/ol&gt;
&lt;dl&gt;
&lt;dt&gt;Theorem 2 (&lt;strong&gt;Nested intervals theorem&lt;/strong&gt;)&lt;/dt&gt;
&lt;dd&gt;Let $\{[a_n,b_n]\}$ be a sequence of nested closed intervals, there exist a unique real number $\xi$ s.t. $\xi\in [a_n,b_n]$ for every $n$.&lt;/dd&gt;
&lt;dt&gt;proof&lt;/dt&gt;
&lt;dd&gt;Notice that $\{a_n\}$ is an increasing and bounded sequence, and thus it has limit $\xi$ s.t. $\xi\geq a_n$ for all $n$. Similarly, the sequence $\{b_n\}$ also has a limit. Combing (ii) of the definition, we have
$$ 
 \lim_{n\to\infty}a_n =   \lim_{n\to\infty}b_n = \xi,
$$
and $a_n\leq \xi\leq b_n$ for all $n$. The left work is to show the uniqueness. Suppose that there exists another $\xi&#39;$ s.t. $a_n\leq \xi&#39;\leq b_n$, we have
$$ 
 |\xi - \xi&#39;|\leq b_n - a_n \to 0,
$$
which means that $\xi = \xi&#39;$.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;$\Box$&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mathematical Analysis | 6 Mean Value Theorem</title>
      <link>http://localhost:1313/posts/analysis_1/math_analysis_6/</link>
      <pubDate>Tue, 06 Apr 2021 10:52:59 +0200</pubDate>
      <guid>http://localhost:1313/posts/analysis_1/math_analysis_6/</guid>
      <description>&lt;h2 id=&#34;1-rolles-theorem&#34;&gt;1. Rolle&amp;rsquo;s Theorem&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;Theorem 1 (Rolle&amp;rsquo;s theorem)&lt;/dt&gt;
&lt;dd&gt;If a function $f$ satisfies&lt;/dd&gt;
&lt;/dl&gt;
&lt;ol&gt;
&lt;li&gt;$f$ is continuous on a closed interval $[a,b]$,&lt;/li&gt;
&lt;li&gt;$f$ is differentiable on $(a,b)$,&lt;/li&gt;
&lt;li&gt;$f(a) = f(b)$,&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;then there exists a number $\xi\in(a,b)$ s.t. $f&#39;(\xi)= 0$.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;proof&lt;/dt&gt;
&lt;dd&gt;Because $f$ is continuous on $[a,b]$, $f$ has maximum and minimum, denoted by $M$ and $m$ respectively. If $m= M$, then $f$ is constant, hence the assertion is true. In the case $m&lt;M$, the assumption $f(a) = f(b)$ implies that at least one of the maximum and minimum is achieved at $\xi\in(a,b)$. Then the Fermat&amp;rsquo;s theorem completes the proof.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;$\Box$&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mathematical Analysis | 5 Derivatives and Differentiations</title>
      <link>http://localhost:1313/posts/analysis_1/math_analysis_5/</link>
      <pubDate>Mon, 05 Apr 2021 10:52:59 +0200</pubDate>
      <guid>http://localhost:1313/posts/analysis_1/math_analysis_5/</guid>
      <description>&lt;h2 id=&#34;1-derivatives&#34;&gt;1. Derivatives&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;Definition 1 (Derivative at $x_0$)&lt;/dt&gt;
&lt;dd&gt;Given a function $f$ defined on an neighbourhood of $x_0$ $U(x_0,\delta)$, we say that $f$ is &lt;code&gt;differentiable&lt;/code&gt; at $x_0$ if the following limit exists
$$ 
\lim_{x\to x_0}\frac{f(x)- f(x_0)}{x-x_0}, 
$$
denoted by $f&#39;(x_0)$.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;According to the definition, we can see that if $f$ has derivative at $x_0$, then it is continuous at $x_0$. But the converse is not true.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Definition 2 (One-sided derivatives)&lt;/dt&gt;
&lt;dd&gt;Given a function $f$ defined on $[x_0,x_0+\delta)$, then it has a right derivative at $x_0$, if the right limit exists
$$ 
\lim_{x\to x_0^+}\frac{f(x)- f(x_0)}{x-x_0}, 
$$
denoted by $f&#39;_{+}(x_0)$.&lt;/dd&gt;
&lt;dt&gt;Theorem 3&lt;/dt&gt;
&lt;dd&gt;$f&#39;(x_0)$ exists iff both $f&#39;_{+}(x_0)$ and $f&#39;_{-}(x_0)$ exist.&lt;/dd&gt;
&lt;dt&gt;Definition 4 (Local maximum)&lt;/dt&gt;
&lt;dd&gt;If there is a neighbourhood $U(x_0,\delta)$ where for any $x\in U(x_0,\delta)$ s.t.
$$ 
 f(x_0)\geq f(x),
$$
we say that $f$ attains its local maximum at $x_0$.&lt;/dd&gt;
&lt;dt&gt;Theorem 5 (Fermat&amp;rsquo;s Theorem)&lt;/dt&gt;
&lt;dd&gt;If $f$ has a local extremum at $x_0$ and if it is differentiable at $x_0$, then $f&#39;(x_0) = 0$.&lt;/dd&gt;
&lt;/dl&gt;
&lt;h2 id=&#34;2-differentials&#34;&gt;2. Differentials&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;Definition 5 (Differential)&lt;/dt&gt;
&lt;dd&gt;We define an increment of $f$ by $\Delta y = f(x_0 + \Delta x) - f(x_0)$. If there exists a constant $A$ s.t.
$$ 
 \Delta y = A\Delta x + o(\Delta x),
$$
we say $f$ has a differential at $x_0$, denoted by $d y|_{x_0} = A\Delta x$.&lt;/dd&gt;
&lt;dt&gt;Theorem 6&lt;/dt&gt;
&lt;dd&gt;$f$ has a differential at $x_0$ iff $f$ is differentiable at $x_0$ and $A = f&#39;(x_0)$.&lt;/dd&gt;
&lt;/dl&gt;</description>
    </item>
    <item>
      <title>Mathematical Analysis | 4 The Continuity of Functions</title>
      <link>http://localhost:1313/posts/analysis_1/math_analysis_4/</link>
      <pubDate>Sun, 04 Apr 2021 10:52:59 +0200</pubDate>
      <guid>http://localhost:1313/posts/analysis_1/math_analysis_4/</guid>
      <description>&lt;h2 id=&#34;1-definitions&#34;&gt;1. Definitions&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;Definition 1 (&lt;strong&gt;Continuity at $x_0$&lt;/strong&gt;)&lt;/dt&gt;
&lt;dd&gt;Given a function $f$ defined on $U(x_0,\delta)$. If $\lim_{x\to x_0} = f(x_0)$, $f$ is said to be &lt;em&gt;continuous at $x_0$&lt;/em&gt;.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;That $f$ is continuous at $x_0$ implies that we can interchange the order of $\lim$ and $f$,
&lt;/p&gt;
$$ 
 \lim_{x\to x_0} = f(\lim{x\to x_0} x).
$$&lt;p&gt;We introduce a new terminology &amp;ldquo;increment&amp;rdquo;, which is defined by $\Delta x = x - x_0$ and $\Delta y = y- y_0 = f(x_0 + \Delta x) - f(x_0)$. Now the continuity of function $f$ at $x_0$ is equivalent to
&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mathematical Analysis | 3 Limit of Functions</title>
      <link>http://localhost:1313/posts/analysis_1/math_analysis_3/</link>
      <pubDate>Sat, 03 Apr 2021 10:52:59 +0200</pubDate>
      <guid>http://localhost:1313/posts/analysis_1/math_analysis_3/</guid>
      <description>&lt;h2 id=&#34;1-limit-of-functions&#34;&gt;1. Limit of Functions&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;Definition 1 (Limit at $\infty$)&lt;/dt&gt;
&lt;dd&gt;Given a function $f$ defined on $[a,\infty)$ and a constant $A$, if for any $\epsilon&gt;0$ there exists $M$ s.t. for any $x\geq M$,
$$ 
 |f(x) - A|&lt;\infty,
$$
we say that $f$ has limit $A$ as $x\to+\infty$, denoted by $\lim_{x\to +\infty}f(x) = A$.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;If $\lim_{x\to +\infty}f(x)= \lim_{x\to -\infty}f(x) = A$, we deonte it by $\lim_{x\to \infty}f(x) = A$.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Definition 2 (Limit at $x_0$)&lt;/dt&gt;
&lt;dd&gt;Given a function $f$ that is well defined on $U^o(x_0,\delta&#39;)$ and a constant $A$, if for any $\epsilon&gt;0$ there exists a $\delta$ s.t.
$$ 
 |f(x)- A|&lt;\infty,
$$
for any $x\in U^o(x_0,\delta)$, we say that $f$ has limit $A$ as $x\to x_0$, denoted by $\lim_{x\to x_0}f(x) = A$.&lt;/dd&gt;
&lt;dt&gt;Definition 3 (One-sided limit)&lt;/dt&gt;
&lt;dd&gt;Given a function $f$ that is well defined on $U^o_+(x_0,\delta&#39;)$ and a constant $A$, if for any $\epsilon&gt;0$ there exists a $\delta$ s.t.
$$ 
 |f(x)- A|&lt;\infty,
$$
for any $x\in U^o_+(x_0,\delta)$, we say that $f$ has right limit $A$ as $x\to x_0$ from right, denoted by $\lim_{x\to x_0^+}f(x) = A$. Similarly, the left limit can be defined.&lt;/dd&gt;
&lt;dt&gt;Theorem 4&lt;/dt&gt;
&lt;dd&gt;$\lim_{x\to x_0}f(x) = A\Leftrightarrow \lim_{x\to x_0^+}f(x) = \lim_{x\to x_0^-}f(x) = A$.&lt;/dd&gt;
&lt;dt&gt;Proposition 5 (Properties)&lt;/dt&gt;
&lt;dd&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;ol&gt;
&lt;li&gt;uniqueness. If $\lim_{x\to x_0}f(x)$ exists, then the limit is unique.&lt;/li&gt;
&lt;li&gt;local boundedness. If $\lim_{x\to x_0}f(x)$ exists, then $f$ is bouned on $U^o(x_0,\delta)$ for some $\delta$.&lt;/li&gt;
&lt;li&gt;signed. If $\lim_{x\to x_0}f(x) = A&gt;0$, then for any $0&lt;r&lt;A$, there exist a $U^o(x_0,\delta)$ on which $f(x)&gt;r&gt;0$.&lt;/li&gt;
&lt;li&gt;ordered. If both $\lim_{x\to x_0}f(x)$ and $\lim_{x\to x_0}g(x)$ exist, and  $f(x)\leq g(x)$ on some $U^o(x_0,\delta)$, then $\lim_{x\to x_0}f(x)\leq \lim_{x\to x_0}g(x)$.&lt;/li&gt;
&lt;li&gt;squeeze. If $\lim_{x\to x_0}f(x) =  \lim_{x\to x_0}g(x) = A$, and $f(x)\leq h(x)\leq g(x)$ on some $U^o(x_0,\delta)$, then  $\lim_{x\to x_0}h(x) = A$.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;2-existence-of-limit&#34;&gt;2. Existence of Limit&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;Theorem 6 (Heine-Cantor)&lt;/dt&gt;
&lt;dd&gt;Suppose $f$ is well defined on $U^o(x_0,\delta&#39;)$. The limit of $f(x)$ exists iff for any sequence $\{x_n\}\subset U^o(x_0,\delta&#39;)$ that is convergent to $x_0$, the sequence $\{f(x_n)\}$  converges to a fixed point.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Proof: &amp;ldquo;$\Rightarrow$&amp;rdquo; is trivial. We only show the inverse. Suppse that  $f(x_n)\to A$ as $n\to\infty$ for all sequences described as the theorem. If $f(x)$ does not converge to $A$ as $x\to x_0$, then there exists $\epsilon_0$ s.t $\forall \delta&gt;0$, there is some $x\in U^o(x_0,\delta)$ with $|f(x)- A|\geq \epsilon_0$. We take $\delta = \delta&#39;/n$, $n = 1,2,\ldots$, and thus obtain a sequence $\{x_n\}$ s.t.
&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mathematical Analysis | 2 Limit of Sequences</title>
      <link>http://localhost:1313/posts/analysis_1/math_analysis_2/</link>
      <pubDate>Fri, 02 Apr 2021 10:52:59 +0200</pubDate>
      <guid>http://localhost:1313/posts/analysis_1/math_analysis_2/</guid>
      <description>&lt;h2 id=&#34;1-limit-of-sequences&#34;&gt;1. Limit of Sequences&lt;/h2&gt;
&lt;p&gt;Given a function $f:\mathbb{N}_{+}\to \mathbb{R}$, we call $f( \mathbb{N}_{+})$ as a &lt;em&gt;sequence&lt;/em&gt;, enumerated as $a_1,a_2,\ldots$, denoted by $\{a_n\}$.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Definition 1 (Convergence)&lt;/dt&gt;
&lt;dd&gt;We say a sequence $\\{a_n\\}$ is &lt;em&gt;convergent&lt;/em&gt; to $a$ if for any $\epsilon&gt;0$, there exits a constant $N$ s.t. for any $n\geq N$,
$$ 
 |a_n - a|&lt;\epsilon.
$$
And the point $a$ is called the &lt;em&gt;limit&lt;/em&gt; of the sequence $\{a_n\}$, denoted by $\lim_{n\to\infty}a_n = a$.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;An equivalent definition of the convergence of a sequence is given by,&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mathematical Analysis | 1 Real Numbers and Functions</title>
      <link>http://localhost:1313/posts/analysis_1/math_analysis_1/</link>
      <pubDate>Thu, 01 Apr 2021 10:52:59 +0200</pubDate>
      <guid>http://localhost:1313/posts/analysis_1/math_analysis_1/</guid>
      <description>&lt;h2 id=&#34;1-real-numbers&#34;&gt;1. Real Numbers&lt;/h2&gt;
&lt;dl&gt;
&lt;dt&gt;Definition 1 (Bounds)&lt;/dt&gt;
&lt;dd&gt;$S\in\mathbb{R}$. We say that $S$ is &lt;em&gt;bounded above&lt;/em&gt; if there exits $M$ s.t. for every $x\in S$ $x\leq M$, and $M$ is called the &lt;em&gt;upper bond&lt;/em&gt; of $S$. Similarly, we say that $S$ is &lt;em&gt;bounded from below&lt;/em&gt; if $x\geq M$, and $M$ is called the &lt;em&gt;lower bound&lt;/em&gt; of $S$.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;We say that $S$ is bounded if its upper bounds and lower bounds exist.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Definition 2 (Supremum and infimum)&lt;/dt&gt;
&lt;dd&gt;Let $\eta$ be an upper bound of $S$. If for any $\alpha&lt;\eta$ there exists $x_0\in S$ s.t. $x_0&gt;\alpha$, then $\eta$ is called the &lt;em&gt;supremum&lt;/em&gt; of $S$, denoted by $\eta = \sup S$. Similarly, $\eta$ is the &lt;em&gt;infimum&lt;/em&gt; of $S$, denoted by $\eta = \inf S$, if for any $\alpha&gt;\eta$, there exits $x_0\in S$ s.t. $x_0&lt;\alpha$.&lt;/dd&gt;
&lt;dt&gt;Theorem 3 (Existence)&lt;/dt&gt;
&lt;dd&gt;If $S$ has an upper bound, then $\sup S$ exists. If $S$ has an lower bound, then $\inf S$ exists.&lt;/dd&gt;
&lt;dt&gt;Corollary 4&lt;/dt&gt;
&lt;dd&gt;Given nonempty sets $A,B$. If $\forall x\in A,\forall y\in B$ $x\leq y$, then $\sup A$ and $\inf B$ exist. Moreover, $\sup A\leq \inf B$.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;proof:
The existence of $\sup A$ and $\inf B$ is immediate by Theorem 3. We show the inequality only. Because $y$ is an upper bound of $A$ for any $y\in B$, $\sup A\leq y$. It suggests that $\sup A$ is a lower bound of $B$, hence $\sup A\leq \inf B$.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
