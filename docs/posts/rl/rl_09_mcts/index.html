<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta property="og:url" content="https://wangchxx.github.io/posts/rl/rl_09_mcts/">
  <meta property="og:site_name" content="My Math Notes">
  <meta property="og:title" content="RL | Multiplayer Monte Carlo Tree Search">
  <meta property="og:description" content="1. Multi-Agent Systems A multi-agent system (MAS) consists of multiple decision-making agents which interact in a shared environment to achieve common or conflicting goals.
MAS research spans a range of problems, such as
how to design MAS to incentivize certain behaviors in agents, how to design algorithms enabling agents to achieve specific goals in a MAS, how information is communicated and propagated among agents. 2. Monte Carlo Tree Search (MCTS) The MCTS focus on the analysis of the most promising moves, expanding the search tree based on random sampling of the search space. MCTS is based on many palyouts, and the result of each playout is then used to weight the nodes.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2021-09-20T23:01:33+02:00">
    <meta property="article:modified_time" content="2021-09-20T23:01:33+02:00">
      <meta property="og:see_also" content="https://wangchxx.github.io/posts/rl/rl_08_dynamics_approximation/">
      <meta property="og:see_also" content="https://wangchxx.github.io/posts/rl/rl_07_policy_gradient/">
      <meta property="og:see_also" content="https://wangchxx.github.io/posts/rl/rl_06_value_function_approximation/">
      <meta property="og:see_also" content="https://wangchxx.github.io/posts/rl/rl_05_temporal_difference/">
      <meta property="og:see_also" content="https://wangchxx.github.io/posts/rl/rl_04_monte_carlo/">
      <meta property="og:see_also" content="https://wangchxx.github.io/posts/rl/rl_03_dynamic_programming/">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="RL | Multiplayer Monte Carlo Tree Search">
  <meta name="twitter:description" content="1. Multi-Agent Systems A multi-agent system (MAS) consists of multiple decision-making agents which interact in a shared environment to achieve common or conflicting goals.
MAS research spans a range of problems, such as
how to design MAS to incentivize certain behaviors in agents, how to design algorithms enabling agents to achieve specific goals in a MAS, how information is communicated and propagated among agents. 2. Monte Carlo Tree Search (MCTS) The MCTS focus on the analysis of the most promising moves, expanding the search tree based on random sampling of the search space. MCTS is based on many palyouts, and the result of each playout is then used to weight the nodes.">

  
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#262d33">
  <title>
    
    My Math Notes - RL | Multiplayer Monte Carlo Tree Search
    
  </title>
  
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;500;600;700&display=swap"
    rel="stylesheet">
  <link rel="stylesheet" href="https://unpkg.com/normalize.css">
  <link rel="stylesheet" type="text/css" media="screen" href="/css/main.css" />
  <link rel="stylesheet" type="text/css" media="screen" href="/css/md.css" />
  <link rel="stylesheet" type="text/css" media="screen" href="/css/syntax.css" />
  <script src="/js/main.js"></script>
</head>
<script>
  try {
    if (!('theme' in localStorage)) {
      localStorage.theme = window.matchMedia('(prefer-color-scheme: dark)').matches ? 'dark' : 'light';
    }
    document.querySelector('html').classList.add(localStorage.theme);
  } catch (e) {
    console.error(e);
  }
</script>
<body>
  <header>
  <h1 class="row gap-1">
    <div id="theme-switcher" class="btn lg-1"></div>
    My Math Notes
  </h1>
  <nav class="row gap-1">
  
    <a href="/">Home</a>
  
    <a href="/categories">Categories</a>
  
    <a href="/series">Series</a>
  
    <a href="/about">About</a>
  
  </nav>
  <hr>
</header>
  
  
<main>
	<h1>RL | Multiplayer Monte Carlo Tree Search</h1>
	<div class="sm-1 mtb-1">
		Posted at &mdash; Sep 20, 2021
		
	</div>
	<p></p>
	<article class="md">
		<h2 id="1-multi-agent-systems">1. Multi-Agent Systems</h2>
<p>A multi-agent system (MAS) consists of multiple decision-making agents which interact in a shared environment to achieve common or conflicting goals.</p>
<p>MAS research spans a range of problems, such as</p>
<ul>
<li>how to design MAS to incentivize certain behaviors in agents,</li>
<li>how to design algorithms enabling agents to achieve specific goals in a MAS,</li>
<li>how information is communicated and propagated among agents.</li>
</ul>
<h2 id="2-monte-carlo-tree-search-mcts">2. Monte Carlo Tree Search (MCTS)</h2>
<p>The MCTS focus on the analysis of the most promising moves, expanding the search tree based on random sampling of the search space. MCTS is based on many palyouts, and the result of each playout is then used to weight the nodes.</p>
<ul>
<li>A <code>playout</code>, also called <code>rollout</code>, is a sequence of state-action-reward tuples until the terminal.</li>
</ul>
<dl>
<dt>Definition (static evaluation function)</dt>
<dd>A static evaluation function (also known as evaluation function or heuristic evaluation function) is a function used to estimate the goodness of a state. The function is called <code>static</code> because it does not take into account the history of the state or explore possible forward moves.</dd>
</dl>
<p>Each round of MCTS consists of four steps:</p>
<ul>
<li>
<p>Selection: start from root node $R$ and select successive child nodes until a leaf node $L$ is reached. The leaf is any node that has a potential child from which no playout has yet been initiated.</p>
</li>
<li>
<p>Expansion: unless $L$ is the terminal state, create child nodes and choose node $C$ from one of them. Child nodes are any valid moves from the state $L$.</p>
</li>
<li>
<p>Simulation: complete one random playout from node $C$.</p>
</li>
<li>
<p>Backpropagation: use the result of the playout to update the information in the nodes on the path from $C$ to $R$.</p>
</li>
</ul>
<p><img src="/img_rl/simple_mcts.png" alt="the number in each node is the wining ratio from this node"></p>
<p>When selecting child nodes, the exploration-exploitation techniques, such as UCT and UCB, can be applied.</p>
<p>In the $n$-agent sequential move games, the MCTS can be quite inefficient since the search space grows exponentially. There are some improvements for MCTS</p>
<ul>
<li>
<p>Paranoid assumption: all other agents are always conspiring against the root agent. This simplifies the game to a 2-agent game.</p>
</li>
<li>
<p>Progressive widening or progressive unpruning: restrict the number optional moves to $[cn^\alpha]$ ,where $n$ is the number of visits to the current node so far.</p>
</li>
<li>
<p>Opponent move abstraction (OMA): The MCTS in its basic form estimates the value of each move $a_d$ at depth $d$ in the precise context of its entire history from the root. These estimators are unbiased, but require large number of simulations. Move abstraction is a technique that generalize context by focusing on only a part of a move&rsquo;s history. OMA ignores past moves of component agents and only considers past moves of the currently moving player.</p>
</li>
</ul>
<h2 id="3-upper-confidence-bounds-applied-to-trees-uct">3. Upper Confidence bounds applied to Trees (UCT)</h2>
<p>In selection, the choice of actions depends on the value the actions at the root node. The value of a state-action node is computed based on the average of the sum of rewards along the edges originating at the node and the values at the corresponding successor nodes. To find an action whose value is within the $\epsilon$-vicinity of that of the best, the depth of the tree needed is proportional to $1/(1-\gamma) \log \frac{1}{\epsilon(1-\gamma)}$, hence the width is proportional to $\frac{K}{\epsilon (1-\gamma)}$.</p>
<p>In the selection step of MCTS, UCT treats it as a multi-armed bandits problem, selecting the action that maximizes
</p>
$$ 
 Q_{d,t}(s,a) + \sqrt{\frac{2\ln N_{d,t}(s)}{N_{d,t}(s,a)}},
$$<p>
where $N_{d,t}(\cdot)$ is the number times state has been visited up to time t at depth $d$.</p>
<h2 id="4-context-generalization">4. Context Generalization</h2>
<p>The count $N_{d,t}(s,a)$ is hard to update, because it depends on the trajectories of states and actions. To speed up training, we need to reduce the trajectory space. This technique is called <code>abstraction</code>. This can be done by reducing dimensionality.</p>
<p>Another idea is to define the pseudo-counts $\hat{N}$.</p>
<ul>
<li>Fitting generative models. fit a density model $p_\theta(s)$ s.t. $p_\theta(s)$ is high even $s$ has never been seen if $s$ is similar to previously seen states.
$$ 
 p_\theta(s) = \frac{\hat{N}(s)}{\hat{n}}, \quad p_{\theta'}(s) = \frac{\hat{N}(s) + 1}{\hat{n}+1}.
$$
It leads to $\hat{N}(s) = \hat{n}p_\theta(s), \hat{n} = \frac{1-p_{\theta'}(s)}{p_{\theta'}(s) - p_\theta(s)} p_\theta(s)$. The model $p_\theta$ can be a deep neural network (learning hashing)</li>
</ul>
<h2 id="5-rapid-action-value-estimation-rave">5. Rapid Action Value Estimation (RAVE)</h2>
<h2 id="5-best-reply-search-brs">5. Best-Reply-Search (BRS)</h2>
<p>One difficulty of MAS is that the width of tree grows exponentially with the number of agents. To solve this problem we need opponent abstraction.</p>
<p>Like Paranoid, BRS assumes that all opponents are playing against the root agent, however, it <strong>restricts the move choices of this coalition</strong>-only the opponent with the strongest move against the root can move, while all other opponents pass. This also simplifies the game to a 2-agent game</p>
<p>But BRS can lead to illegal game states if passing is not allowed in the game. This motivates BRS+, which assumes access to a static move ordering function. Its basic idea is that whenever an opponent does not have the strongest move against the root, this opponent play the move ranked highest by the move ordering (a fixed move).</p>
<h2 id="references">References</h2>
<ul>
<li>
<p>[1] L. Kocsis and C. Szepesvári, “Bandit Based Monte-Carlo Planning,” in Machine Learning: ECML 2006, vol. 4212, J. Fürnkranz, T. Scheffer, and M. Spiliopoulou, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2006, pp. 282–293. doi: 10.1007/11871842_29.</p>
</li>
<li>
<p>[2] H. Baier and M. Kaisers, “ME-MCTS: Online Generalization by Combining Multiple Value Estimators,” in Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, Montreal, Canada, Aug. 2021, pp. 4032–4038. doi: 10.24963/ijcai.2021/555.</p>
</li>
<li>
<p>[3] J. He, M. Suau, and F. A. Oliehoek, “Influence-Augmented Online Planning for Complex Environments,” arXiv:2010.11038 [cs], Jun. 2021, Accessed: Sep. 20, 2021. [Online]. Available: <a href="http://arxiv.org/abs/2010.11038">http://arxiv.org/abs/2010.11038</a></p>
</li>
<li>
<p>[4] S. Srinivasan, E. Talvitie, and M. Bowling, “Improving Exploration in UCT Using Local Manifolds,” p. 7.</p>
</li>
<li>
<p>[5] H. Baier and M. Kaisers, “Guiding Multiplayer MCTS by Focusing on Yourself,” in 2020 IEEE Conference on Games (CoG), Osaka, Japan, Aug. 2020, pp. 550–557. doi: 10.1109/CoG47356.2020.9231603.</p>
</li>
<li>
<p>[6] S. Gelly and D. Silver, “Monte-Carlo tree search and rapid action value estimation in computer Go,” Artificial Intelligence, vol. 175, no. 11, pp. 1856–1875, Jul. 2011, doi: 10.1016/j.artint.2011.03.007.</p>
</li>
</ul>

	</article>
</main>
	
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: '\\[', right: '\\]', display: true},   
        {left: '$$', right: '$$', display: true},     
        {left: '$', right: '$', display: false},  
      ],
      throwOnError : false
    });
  });
</script>

	

	

	



  <footer class="row row-mob al-c-mob col-rev-mob sm-2-mob  jc-bt mtb-2">
  <p>
    © Copyright notice |
    <a href="https://github.com/mivinci/hugo-theme-minima" target="_blank" rel="noopener noreferrer">Minima</a> theme on
    <a href="https://gohugo.io" target="_blank" rel="noopener noreferrer">Hugo</a>
  </p>
  <p class="row gap-0_5">
    
      <a class="icon" href="https://github.com/wangchxx" title="github">
      
        <svg fill="#63636f" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
      
      </a>
    
  </p>
</footer>
</body>
</html>