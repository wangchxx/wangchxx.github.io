<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>RL | Multiplayer Monte Carlo Tree Search | My Notes</title>
<meta name="keywords" content="">
<meta name="description" content="1. Multi-Agent Systems
A multi-agent system (MAS) consists of multiple decision-making agents which interact in a shared environment to achieve common or conflicting goals.
MAS research spans a range of problems, such as

how to design MAS to incentivize certain behaviors in agents,
how to design algorithms enabling agents to achieve specific goals in a MAS,
how information is communicated and propagated among agents.

2. Monte Carlo Tree Search (MCTS)
The MCTS focus on the analysis of the most promising moves, expanding the search tree based on random sampling of the search space. MCTS is based on many palyouts, and the result of each playout is then used to weight the nodes.">
<meta name="author" content="Chaohua Wang">
<link rel="canonical" href="http://localhost:1313/posts/rl/rl_09_mcts/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css" integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/rl/rl_09_mcts/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: '\\[', right: '\\]', display: true},   
        {left: '$$', right: '$$', display: true},     
        {left: '$', right: '$', display: false},  
      ],
      throwOnError : false
    });
  });
</script>




</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="My Notes (Alt + H)">My Notes</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/series/" title="Series">
                    <span>Series</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/categories" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      RL | Multiplayer Monte Carlo Tree Search
    </h1>
    <div class="post-meta"><span title='2021-09-20 23:01:33 +0200 +0200'>September 20, 2021</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Chaohua Wang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#1-multi-agent-systems" aria-label="1. Multi-Agent Systems">1. Multi-Agent Systems</a></li>
                <li>
                    <a href="#2-monte-carlo-tree-search-mcts" aria-label="2. Monte Carlo Tree Search (MCTS)">2. Monte Carlo Tree Search (MCTS)</a></li>
                <li>
                    <a href="#3-upper-confidence-bounds-applied-to-trees-uct" aria-label="3. Upper Confidence bounds applied to Trees (UCT)">3. Upper Confidence bounds applied to Trees (UCT)</a></li>
                <li>
                    <a href="#4-context-generalization" aria-label="4. Context Generalization">4. Context Generalization</a></li>
                <li>
                    <a href="#5-rapid-action-value-estimation-rave" aria-label="5. Rapid Action Value Estimation (RAVE)">5. Rapid Action Value Estimation (RAVE)</a></li>
                <li>
                    <a href="#5-best-reply-search-brs" aria-label="5. Best-Reply-Search (BRS)">5. Best-Reply-Search (BRS)</a></li>
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="1-multi-agent-systems">1. Multi-Agent Systems<a hidden class="anchor" aria-hidden="true" href="#1-multi-agent-systems">#</a></h2>
<p>A multi-agent system (MAS) consists of multiple decision-making agents which interact in a shared environment to achieve common or conflicting goals.</p>
<p>MAS research spans a range of problems, such as</p>
<ul>
<li>how to design MAS to incentivize certain behaviors in agents,</li>
<li>how to design algorithms enabling agents to achieve specific goals in a MAS,</li>
<li>how information is communicated and propagated among agents.</li>
</ul>
<h2 id="2-monte-carlo-tree-search-mcts">2. Monte Carlo Tree Search (MCTS)<a hidden class="anchor" aria-hidden="true" href="#2-monte-carlo-tree-search-mcts">#</a></h2>
<p>The MCTS focus on the analysis of the most promising moves, expanding the search tree based on random sampling of the search space. MCTS is based on many palyouts, and the result of each playout is then used to weight the nodes.</p>
<ul>
<li>A <code>playout</code>, also called <code>rollout</code>, is a sequence of state-action-reward tuples until the terminal.</li>
</ul>
<dl>
<dt>Definition (static evaluation function)</dt>
<dd>A static evaluation function (also known as evaluation function or heuristic evaluation function) is a function used to estimate the goodness of a state. The function is called <code>static</code> because it does not take into account the history of the state or explore possible forward moves.</dd>
</dl>
<p>Each round of MCTS consists of four steps:</p>
<ul>
<li>
<p>Selection: start from root node $R$ and select successive child nodes until a leaf node $L$ is reached. The leaf is any node that has a potential child from which no playout has yet been initiated.</p>
</li>
<li>
<p>Expansion: unless $L$ is the terminal state, create child nodes and choose node $C$ from one of them. Child nodes are any valid moves from the state $L$.</p>
</li>
<li>
<p>Simulation: complete one random playout from node $C$.</p>
</li>
<li>
<p>Backpropagation: use the result of the playout to update the information in the nodes on the path from $C$ to $R$.</p>
</li>
</ul>
<p><img alt="the number in each node is the wining ratio from this node" loading="lazy" src="/img_rl/simple_mcts.png"></p>
<p>When selecting child nodes, the exploration-exploitation techniques, such as UCT and UCB, can be applied.</p>
<p>In the $n$-agent sequential move games, the MCTS can be quite inefficient since the search space grows exponentially. There are some improvements for MCTS</p>
<ul>
<li>
<p>Paranoid assumption: all other agents are always conspiring against the root agent. This simplifies the game to a 2-agent game.</p>
</li>
<li>
<p>Progressive widening or progressive unpruning: restrict the number optional moves to $[cn^\alpha]$ ,where $n$ is the number of visits to the current node so far.</p>
</li>
<li>
<p>Opponent move abstraction (OMA): The MCTS in its basic form estimates the value of each move $a_d$ at depth $d$ in the precise context of its entire history from the root. These estimators are unbiased, but require large number of simulations. Move abstraction is a technique that generalize context by focusing on only a part of a move&rsquo;s history. OMA ignores past moves of component agents and only considers past moves of the currently moving player.</p>
</li>
</ul>
<h2 id="3-upper-confidence-bounds-applied-to-trees-uct">3. Upper Confidence bounds applied to Trees (UCT)<a hidden class="anchor" aria-hidden="true" href="#3-upper-confidence-bounds-applied-to-trees-uct">#</a></h2>
<p>In selection, the choice of actions depends on the value the actions at the root node. The value of a state-action node is computed based on the average of the sum of rewards along the edges originating at the node and the values at the corresponding successor nodes. To find an action whose value is within the $\epsilon$-vicinity of that of the best, the depth of the tree needed is proportional to $1/(1-\gamma) \log \frac{1}{\epsilon(1-\gamma)}$, hence the width is proportional to $\frac{K}{\epsilon (1-\gamma)}$.</p>
<p>In the selection step of MCTS, UCT treats it as a multi-armed bandits problem, selecting the action that maximizes
</p>
$$ 
 Q_{d,t}(s,a) + \sqrt{\frac{2\ln N_{d,t}(s)}{N_{d,t}(s,a)}},
$$<p>
where $N_{d,t}(\cdot)$ is the number times state has been visited up to time t at depth $d$.</p>
<h2 id="4-context-generalization">4. Context Generalization<a hidden class="anchor" aria-hidden="true" href="#4-context-generalization">#</a></h2>
<p>The count $N_{d,t}(s,a)$ is hard to update, because it depends on the trajectories of states and actions. To speed up training, we need to reduce the trajectory space. This technique is called <code>abstraction</code>. This can be done by reducing dimensionality.</p>
<p>Another idea is to define the pseudo-counts $\hat{N}$.</p>
<ul>
<li>Fitting generative models. fit a density model $p_\theta(s)$ s.t. $p_\theta(s)$ is high even $s$ has never been seen if $s$ is similar to previously seen states.
$$ 
 p_\theta(s) = \frac{\hat{N}(s)}{\hat{n}}, \quad p_{\theta'}(s) = \frac{\hat{N}(s) + 1}{\hat{n}+1}.
$$
It leads to $\hat{N}(s) = \hat{n}p_\theta(s), \hat{n} = \frac{1-p_{\theta'}(s)}{p_{\theta'}(s) - p_\theta(s)} p_\theta(s)$. The model $p_\theta$ can be a deep neural network (learning hashing)</li>
</ul>
<h2 id="5-rapid-action-value-estimation-rave">5. Rapid Action Value Estimation (RAVE)<a hidden class="anchor" aria-hidden="true" href="#5-rapid-action-value-estimation-rave">#</a></h2>
<h2 id="5-best-reply-search-brs">5. Best-Reply-Search (BRS)<a hidden class="anchor" aria-hidden="true" href="#5-best-reply-search-brs">#</a></h2>
<p>One difficulty of MAS is that the width of tree grows exponentially with the number of agents. To solve this problem we need opponent abstraction.</p>
<p>Like Paranoid, BRS assumes that all opponents are playing against the root agent, however, it <strong>restricts the move choices of this coalition</strong>-only the opponent with the strongest move against the root can move, while all other opponents pass. This also simplifies the game to a 2-agent game</p>
<p>But BRS can lead to illegal game states if passing is not allowed in the game. This motivates BRS+, which assumes access to a static move ordering function. Its basic idea is that whenever an opponent does not have the strongest move against the root, this opponent play the move ranked highest by the move ordering (a fixed move).</p>
<h2 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h2>
<ul>
<li>
<p>[1] L. Kocsis and C. Szepesvári, “Bandit Based Monte-Carlo Planning,” in Machine Learning: ECML 2006, vol. 4212, J. Fürnkranz, T. Scheffer, and M. Spiliopoulou, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2006, pp. 282–293. doi: 10.1007/11871842_29.</p>
</li>
<li>
<p>[2] H. Baier and M. Kaisers, “ME-MCTS: Online Generalization by Combining Multiple Value Estimators,” in Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, Montreal, Canada, Aug. 2021, pp. 4032–4038. doi: 10.24963/ijcai.2021/555.</p>
</li>
<li>
<p>[3] J. He, M. Suau, and F. A. Oliehoek, “Influence-Augmented Online Planning for Complex Environments,” arXiv:2010.11038 [cs], Jun. 2021, Accessed: Sep. 20, 2021. [Online]. Available: <a href="http://arxiv.org/abs/2010.11038">http://arxiv.org/abs/2010.11038</a></p>
</li>
<li>
<p>[4] S. Srinivasan, E. Talvitie, and M. Bowling, “Improving Exploration in UCT Using Local Manifolds,” p. 7.</p>
</li>
<li>
<p>[5] H. Baier and M. Kaisers, “Guiding Multiplayer MCTS by Focusing on Yourself,” in 2020 IEEE Conference on Games (CoG), Osaka, Japan, Aug. 2020, pp. 550–557. doi: 10.1109/CoG47356.2020.9231603.</p>
</li>
<li>
<p>[6] S. Gelly and D. Silver, “Monte-Carlo tree search and rapid action value estimation in computer Go,” Artificial Intelligence, vol. 175, no. 11, pp. 1856–1875, Jul. 2011, doi: 10.1016/j.artint.2011.03.007.</p>
</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="prev" href="http://localhost:1313/posts/diffusion_1_ddmp/">
    <span class="title">« Prev</span>
    <br>
    <span>DL | Diffusion Models 1 - DDMP</span>
  </a>
  <a class="next" href="http://localhost:1313/posts/rl/rl_08_dynamics_approximation/">
    <span class="title">Next »</span>
    <br>
    <span>RL | Dynamics Approximation for Model-Based RL</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="http://localhost:1313/">My Notes</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
