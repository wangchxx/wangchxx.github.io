<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>DL | Diffusion Models 1 - DDMP | My Notes</title>
<meta name="keywords" content="">
<meta name="description" content="What?
A diffusion probabilistic model is a parameterized Markov chain that gradually adds noise to the data and then learn to reverse the diffusion process to generate data samples from noise.

Why?
Compared with other AI tasks, image generation is harder, since it does not have a standard answer. To solve this issue, GAN and VAE are propsed.


GAN uses another model (discriminator) to decide the quality of generated images.">
<meta name="author" content="Chaohua Wang">
<link rel="canonical" href="https://wangchxx.github.io/posts/diffusion_1_ddmp/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.14b508198d6c32523f8895e6c6606da34de25e588fe390ef44ad07a0cc7dad33.css" integrity="sha256-FLUIGY1sMlI/iJXmxmBto03iXliP45DvRK0HoMx9rTM=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://wangchxx.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://wangchxx.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://wangchxx.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://wangchxx.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://wangchxx.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://wangchxx.github.io/posts/diffusion_1_ddmp/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: '\\[', right: '\\]', display: true},   
        {left: '$$', right: '$$', display: true},     
        {left: '$', right: '$', display: false},  
      ],
      throwOnError : false
    });
  });
</script>



<meta property="og:title" content="DL | Diffusion Models 1 - DDMP">
<meta property="og:description" content="What?
A diffusion probabilistic model is a parameterized Markov chain that gradually adds noise to the data and then learn to reverse the diffusion process to generate data samples from noise.

Why?
Compared with other AI tasks, image generation is harder, since it does not have a standard answer. To solve this issue, GAN and VAE are propsed.


GAN uses another model (discriminator) to decide the quality of generated images.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://wangchxx.github.io/posts/diffusion_1_ddmp/"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2024-10-21T04:34:23+08:00">
<meta property="article:modified_time" content="2024-10-21T04:34:23+08:00">



<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="DL | Diffusion Models 1 - DDMP">
<meta name="twitter:description" content="What?
A diffusion probabilistic model is a parameterized Markov chain that gradually adds noise to the data and then learn to reverse the diffusion process to generate data samples from noise.

Why?
Compared with other AI tasks, image generation is harder, since it does not have a standard answer. To solve this issue, GAN and VAE are propsed.


GAN uses another model (discriminator) to decide the quality of generated images.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://wangchxx.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "DL | Diffusion Models 1 - DDMP",
      "item": "https://wangchxx.github.io/posts/diffusion_1_ddmp/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "DL | Diffusion Models 1 - DDMP",
  "name": "DL | Diffusion Models 1 - DDMP",
  "description": "What? A diffusion probabilistic model is a parameterized Markov chain that gradually adds noise to the data and then learn to reverse the diffusion process to generate data samples from noise.\nWhy? Compared with other AI tasks, image generation is harder, since it does not have a standard answer. To solve this issue, GAN and VAE are propsed.\nGAN uses another model (discriminator) to decide the quality of generated images.\n",
  "keywords": [
    
  ],
  "articleBody": "What? A diffusion probabilistic model is a parameterized Markov chain that gradually adds noise to the data and then learn to reverse the diffusion process to generate data samples from noise.\nWhy? Compared with other AI tasks, image generation is harder, since it does not have a standard answer. To solve this issue, GAN and VAE are propsed.\nGAN uses another model (discriminator) to decide the quality of generated images.\nVAE learns how to compress an image into a latent vector $z$ and then learns how to reconstruct the image from $z$. Then for each generated image, there exists a standard answer.GAN is able to generate images with good quality, but its training is unstable. Is there a model that is as powerful as GAN but simpler for training?\nHow? Forward process Given a data point sampled from a real data distribution $x_0\\sim q(x)$, the forward process is defined by\n$$ q(x_t|x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1-\\beta_t}x_{t-1}, \\beta_t I),\\quad q(x_{1:T}|x_0) = \\prod_{t=1}^T q(x_t|x_{t-1}). $$A nice property of the forward process is that it admits sampling $x_t$ at an arbitrary timestep $t$ in closed form:\n$$ \\begin{equation} q(x_t|x_0) = \\mathcal{N}(x_t; \\sqrt{\\bar{\\alpha}_t} x_0, (1-\\bar{\\alpha}_{t})I), \\end{equation} $$where $\\alpha_t := 1-\\beta_t$ and $\\bar{\\alpha}_t:= \\prod_{s=0}^t \\alpha_s$. To make sure that $q(x_t|x_0)$ is convergent, we need $\\bar{\\alpha}_t \\to C$ as $t\\to\\infty$. It can be guaranteed by setting $\\beta_t\\in (0,1)$ as an increasing sequence and therefore $\\bar{\\alpha}_1\u003e\\cdots\u003e\\bar{\\alpha}_T$.\nReverse process If we can reverse the above process and sample from $q(x_{t-1}|x_t)$, we will be able to recreate the true sample from a Gaussian noise input $x_T\\sim N(0, I)$. Note that if $\\beta_t$ is small enough, $q(x_{t-1}|x_t)$ will also be Gaussian (==We will prove it in Diffusion-model-3==). However, we cannot easily estimate $q(x_{x-1}|x_t)$ because it needs to use the entire dataset. So we try to estimate it through a model $p_\\theta(x_{t-1}|x_t)$. We set\n$$ p_\\theta(x_{t-1}|x_t) = \\mathcal{N}(x_{t-1}; \\mu_\\theta(x_t, t), \\Sigma_\\theta(x_t, t));\\quad p_\\theta(x_{0:T}) = p(x_T)\\prod_{t=1}^T p_\\theta(x_{t-1}|x_t). $$But how to define the loss function? Fitting the mean and variance of added noise from the step $q(x_{t-1}|x_t)$ is unrealistic.\nConditional posterior\nIt is noteworthy that the reverse conditional probability is tractable when conditioned on $x_0$:\n$$ q(x_{t-1}|x_t, x_0) = \\mathcal{N}(x_{t-1}; \\tilde{\\mu}_t(x_t, x_0), \\tilde{\\beta}_t I), $$where\n$$ \\begin{equation} \\tilde{\\mu}_t(x_t, x_0) := \\frac{\\sqrt{\\alpha_t}(1-\\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}x_t +\\frac{\\bar{\\alpha}_{t-1}\\beta_t}{1-\\bar{\\alpha}_t}x_0;\\quad \\tilde{\\beta}_t:= \\frac{1-\\bar{\\alpha}_{t-1}}{1-\\bar{\\alpha}_t}\\beta_t. \\end{equation} $$See Proof of conditional posterior.\nLoss function\nThen we can use the variational lower bound to optimize the negative log-likehood.\n$$ \\begin{aligned} -\\log p_{\\theta}(x_{0}) \u0026\\leq -\\log p_{\\theta}(x_{0}) + D_{KL}(q(x_{1:T}|x_{0})\\|p_{\\theta}(x_{1:T}|x_{0})) \\\\ \u0026= -\\log p_{\\theta}(x_{0}) + \\mathbb{E}_{q}\\left[ \\log \\frac{q(x_{1:T}|x_{0})}{p_{\\theta}(x_{0:T})/p_{\\theta}(x_{0})} \\right]\\\\ \u0026=-\\log p_{\\theta}(x_{0}) + \\mathbb{E}_{q}\\left[ \\log \\frac{q(x_{1:T}|x_{0})}{p_{\\theta}(x_{0:T})} +\\log p_{\\theta}(x_{0}) \\right]\\\\ \u0026=\\mathbb{E}_{q}\\left[ \\log \\frac{q(x_{1:T}|x_{0})}{p_{\\theta}(x_{0:T})} \\right] := L_{VLB} \\end{aligned} $$Then we rewrite $L_{VLB}$ in terms of $q(x_{t-1}|x_{t},x_{0})$:\n$$ \\begin{align} L_{VLB} \u0026= L_{T} + L_{T-1} + \\cdots + L_{0}, \\\\ \\text{where} \\; L_{T} \u0026 = D_{KL}(q(x_{T}|x_{0})\\|p_{\\theta}(x_{T})), \\\\ L_{t} \u0026 = D_{KL}(q(x_{t}|x_{t+1},x_{0})\\| p_{\\theta}(x_{t}|x_{t+1})),\\; 1\\leq t\\leq T-1, \\\\ L_{0} \u0026 = -\\log p_{\\theta}(x_{0}|x_{1}). \\end{align} $$See Proof of loss. $L_{T}$ is constant because $x_{T}$ is a Gaussian noise. $L_{0}$ is modeled using a separate decoder. $L_{t}$ compares two Gaussian distributions and therefore can be computed in closed form.\nSimplification of $L_{t}$\nIt is known that the KL divergence between two Gaussian distributions $\\mathcal{N}(\\mu_{p}, \\Sigma_{p})$ and $\\mathcal{N}(\\mu_{q},\\Sigma_{q})$ is\n$$ D_{KL}(p\\|q) = \\frac{1}{2} \\left[ \\log \\frac{|\\Sigma_{q}|}{|\\Sigma_{p}|} + (\\mu_{p} -\\mu_{q})^T \\Sigma_{q}^{-1}(\\mu_{q} - \\mu_{p}) + Tr(\\Sigma_{q}^{-1}\\Sigma_{p}) \\right] + C. $$Since the authors set $\\Sigma_{\\theta}(x_{t}, t) = \\sigma_{t}^2 I$, where $\\sigma_{t}$ is not learnable. We can simplify $L_{t}$ as\n$$ \\begin{equation} L_{t} = \\frac{1}{2\\|\\Sigma_{\\theta}(x_{t},t)\\|_{2}^2} \\|\\tilde{\\mu}(x_{t},x_{0}) - \\mu_{\\theta}(x_{t},t)\\|^2 + C. \\end{equation} $$We can expand the above loss by reparameterizing $q(x_t|x_0) = \\mathcal{N}(x_t; \\sqrt{\\bar{\\alpha}_t} x_0, (1-\\bar{\\alpha})I)$ as $x_{t}(x_{0}, \\epsilon) = \\sqrt{ \\bar{\\alpha}_{t} }x_{0} + \\sqrt{ 1-\\bar{\\alpha}_{t} }\\epsilon$ for $\\epsilon\\sim\\mathcal{N}(0, I)$:\n$$ \\begin{aligned} \\tilde{\\mu}_{t} \u0026= \\frac{\\sqrt{\\alpha_t}(1-\\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}x_t +\\frac{\\bar{\\alpha}_{t-1}\\beta_t}{1-\\bar{\\alpha}_t}{\\color{green}x_0} \\\\ \u0026=\\frac{\\sqrt{\\alpha_t}(1-\\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}x_t +\\frac{\\bar{\\alpha}_{t-1}\\beta_t}{1-\\bar{\\alpha}_t} {\\color{green} \\frac{1}{\\sqrt{ \\bar{\\alpha}_{t} }}(x_{t} - \\sqrt{ 1-\\bar{\\alpha}_{t} }\\epsilon)} \\\\ \u0026=\\frac{1}{\\sqrt{ \\alpha_{t} }}\\left( x_{t} - \\frac{1-\\alpha_{t}}{\\sqrt{ 1-\\bar{\\alpha}_{t} }} \\epsilon \\right) \\end{aligned} $$Instead of approximating $\\tilde{\\mu}_{t}$ by $\\mu_{\\theta}$ directly, we can also estimate the noise $\\epsilon$ using $\\epsilon_{\\theta}(x_{t}, t)$ (like ResNet) by setting\n$$ \\begin{align} \\mu_{\\theta}(x_{t}, t) = \\tilde{\\mu}_{t}(x_{t}, t) \u0026= \\frac{1}{\\sqrt{ \\alpha_{t} }}\\left( x_{t} - \\frac{1-\\alpha_{t}}{\\sqrt{ 1-\\bar{\\alpha}_{t} }} \\epsilon_{\\theta}(x_{t}, t) \\right).\\\\ \\end{align} $$Therefore, we can rewrite the loss function $L_{t}$ as\n$$ \\begin{align} L_{t} \u0026= \\mathbb{E}_{x_{0}, \\epsilon} \\left[\\frac{(1-\\alpha_{t})^2}{2 \\alpha_{t}(1-\\bar{\\alpha}_{t})\\|\\Sigma_{\\theta}(x_{t},t)\\|_{2}^2} \\| \\epsilon - \\epsilon_{\\theta}(x_{t},t)\\|^2 \\right] + C \\\\ \u0026 = \\mathbb{E}_{x_{0}, \\epsilon} \\left[\\frac{(1-\\alpha_{t})^2}{2 \\alpha_{t}(1-\\bar{\\alpha}_{t})\\|\\Sigma_{\\theta}(x_{t},t)\\|_{2}^2} \\| \\epsilon - \\epsilon_{\\theta}({\\color{green}\\sqrt{ \\bar{\\alpha}_{t} }x_{0} + \\sqrt{ 1-\\bar{\\alpha}_{t} }\\epsilon},t)\\|^2 \\right] + C \\end{align} $$Algorithm Empirically, the authors found that training the diffusion model works better with a simplified objective that ignores the weighting term:\n$$ L_{t}^{simple} = \\mathbb{E}_{x_{0}, \\epsilon} \\left[\\| \\epsilon - \\epsilon_{\\theta}(\\sqrt{ \\bar{\\alpha}_{t} }x_{0} + \\sqrt{ 1-\\bar{\\alpha}_{t} }\\epsilon,t)\\|^2 \\right]. $$\nSupplementary Langevin dynamics Langevin dynamics is a concept from physics, developed for statistically modeling molecular systems. Combined with stochastic gradient descent, stochastic gradient Langevin dynamics can produce samples from a probability distribution $p(x)$ using only gradients $\\nabla_{x} \\log p(x)$ in a Markov chain of updates: $$ x_{t} = x_{t-1} + \\frac{\\delta}{2}\\nabla_{x} \\log p(x_{t-1}) + \\sqrt{ \\delta }\\epsilon_{t},\\quad \\epsilon_{t}\\sim \\mathcal{N}(0,I), $$ where $\\delta$ is the step size. When $T\\to \\infty$, $\\epsilon\\to 0$, $x_{T}\\sim p(x)$.\nWe can see that we only need to know the gradients $\\nabla_{x} \\log p(x)$ (score function) to sample data from $p(x)$.\nLet $(x, \\tilde{x})$ be a pair of clean and corrupted data. The idea of denoising score matching is to estimate the score function of the noise-corrupted data distribution $q_{\\sigma}(\\tilde{x})$, and the objective is shown to be equivalent to $$ \\mathbb{E}_{q_{\\sigma}(\\tilde{x}|x) p(x)} [\\|s(\\tilde{x}, \\theta) - \\nabla_{x}\\log q_{\\sigma}(\\tilde{x}|x)\\|_{2}^2]. $$ The schedule of increasing noise levels resembles the forward diffusion process $q(x_{t}|x_{0})$. If we use the diffusion process annotation, the score approximates $s_{\\theta}(x_{t}, t)\\approx \\nabla_{x_{t}}q(x_{t}|x_{0})$. Note that given a Gaussian distribution $x\\sim\\mathcal{N}(\\mu,\\sigma^2I)$, its score function is $$ \\nabla_{x} \\log p(x) = - \\frac{x-\\mu}{\\sigma^2} = - \\frac{\\epsilon}{\\sigma}, \\quad \\epsilon\\sim \\mathcal{N}(0,I). $$ Recall that $q(x_{t}|x_{0})\\sim \\mathcal{N}(x_t; \\sqrt{\\bar{\\alpha}_t} x_0, (1-\\bar{\\alpha})I)$ and therefore, $$ s_{\\theta}(x_{t},t) \\approx \\nabla_{x_{t}}\\log q(x_{t}) = \\mathbb{E}_{q(x_{0})}[\\nabla_{x_{t}}q(x_{t}|x_{0})] = - \\frac{\\epsilon}{\\sqrt{ 1-\\bar{\\alpha}_{t} }}, $$ which is equivalent to the loss function $L_{t}$ in DDPM.\nProof of conditional posterior $p(x_{t-1}|x_t,x_0)$ Using Bayes’ rule, we have $$ \\begin{aligned} q(x_{t-1}|x_{t}, x_{0}) \u0026= q(x_{t}|x_{t}, x_{0}) \\frac{q(x_{t-1}|x_{0})}{q(x_{t}|x_{0})} \\\\ \u0026 \\propto \\exp\\left( -\\frac{1}{2}\\left( \\frac{(x_{t}- \\sqrt{ \\alpha_{t} }x_{t-1})^2}{\\beta_{t}} + \\frac{(x_{t-1}- \\sqrt{ \\bar{\\alpha}_{t-1} }x_{0})^2}{1-\\bar{\\alpha}_{t-1}} - \\frac{(x_{t}- \\sqrt{ \\bar{\\alpha}_{t} }x_{0})^2}{1-\\bar{\\alpha}_{t}} \\right) \\right) \\\\ \u0026 \\propto \\exp\\left( -\\frac{1}{2}\\left( \\frac{- 2\\sqrt{ \\alpha_{t}} x_{t}{\\color{blue}x_{t-1}} + \\alpha_{t} \\color{red}x_{t-1}^2}{\\beta_{t}} + \\frac{ {\\color{red}x_{t-1}^2}- 2\\sqrt{ \\bar{\\alpha}_{t-1} }x_{0}{\\color{blue}{x_{t-1}}} }{1-\\bar{\\alpha}_{t-1}} \\right) \\right) \\\\ \u0026 \\exp\\left( -\\frac{1}{2} \\left( {\\color{red} \\left( \\frac{\\alpha_{t}}{\\beta_{t}} + \\frac{1}{1-\\bar{\\alpha}_{t-1}} \\right)x_{t-1}^2} - {\\color{blue}\\left( \\frac{2\\sqrt{ \\alpha_{t} }}{\\beta_{t}} x_{t} + \\frac{2\\sqrt{\\bar{\\alpha}_{t-1}}}{1-\\bar{\\alpha}_{t-1}} \\right) x_{t-1}} \\right) \\right) \\end{aligned} $$ By completing the square, we have $$ \\begin{aligned} \\tilde{\\beta}_{t} \u0026= \\frac{1}{\\left( \\frac{\\alpha_{t}}{\\beta_{t}} + \\frac{1}{1-\\bar{\\alpha}_{t-1}} \\right)} = \\frac{1-\\bar{\\alpha}_{t-1}}{1-\\bar{\\alpha}_{t}}\\beta_{t}, \\\\ \\tilde{\\mu}_{t} \u0026= \\left( \\frac{2\\sqrt{ \\alpha_{t} }}{\\beta_{t}} x_{t} + \\frac{2\\sqrt{\\bar{\\alpha}_{t-1}}}{1-\\bar{\\alpha}_{t-1}} \\right) / \\tilde{\\beta}_{t} = \\frac{\\sqrt{\\alpha_t}(1-\\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}x_t +\\frac{\\bar{\\alpha}_{t-1}\\beta_t}{1-\\bar{\\alpha}_t}x_0. \\end{aligned} $$Proof of Loss function $L_{VLB}$ $$ \\begin{aligned} L_{VLB} \u0026= \\mathbb{E}_{q}\\left[ \\log \\frac{q(x_{1:T}|x_{0})}{p_{\\theta}(x_{0:T})} \\right] \\\\ \u0026= \\mathbb{E}_{q}\\left[ \\log \\frac{\\prod_{t=1}^Tq(x_{t}|x_{t-1})}{p_{\\theta}(x_{T})\\prod_{t=1}^T p_{\\theta}(x_{t-1}|x_{t})} \\right] \\\\ \u0026= \\mathbb{E}_{q}\\left[ -\\log p_{\\theta}(x_{T}) + \\sum_{t=2}^T \\log \\frac{ q(x_{t}|x_{t-1})}{p_{\\theta}(x_{t-1}|x_{t})} + \\log \\frac{q(x_{1}|x_{0})}{p_{\\theta}(x_{0}|x_{1})} \\right] \\\\ \u0026= \\mathbb{E}_{q}\\left[ -\\log p_{\\theta}(x_{T}) + \\sum_{t=2}^T \\log \\frac{ q(x_{t}|x_{t-1}, {\\color{red}{x_{0}}})}{p_{\\theta}(x_{t-1}|x_{t})} + \\log \\frac{q(x_{1}|x_{0})}{p_{\\theta}(x_{0}|x_{1})} \\right] \\\\ \u0026= \\mathbb{E}_{q}\\left[ -\\log p_{\\theta}(x_{T}) + \\sum_{t=2}^T \\log \\frac{ q(x_{t-1}|x_{t}, x_{0})}{p_{\\theta}(x_{t-1}|x_{t})} \\cdot \\frac{q(x_{t}|x_{0})}{q(x_{t-1}|x_{0})} + \\log \\frac{q(x_{1}|x_{0})}{p_{\\theta}(x_{0}|x_{1})} \\right] \\\\ \u0026= \\mathbb{E}_{q}\\left[ -\\log p_{\\theta}(x_{T}) + \\sum_{t=2}^T \\log \\frac{ q(x_{t-1}|x_{t}, x_{0})}{p_{\\theta}(x_{t-1}|x_{t})} + \\sum_{t=2}^T \\log \\frac{q(x_{t}|x_{0})}{q(x_{t-1}|x_{0})} + \\log \\frac{q(x_{1}|x_{0})}{p_{\\theta}(x_{0}|x_{1})} \\right] \\\\ \u0026= \\mathbb{E}_{q}\\left[ -\\log p_{\\theta}(x_{T}) + \\sum_{t=2}^T \\log \\frac{ q(x_{t-1}|x_{t}, x_{0})}{p_{\\theta}(x_{t-1}|x_{t})} + \\log \\frac{q(x_{T}|x_{0})}{q(x_{1}|x_{0})} + \\log \\frac{q(x_{1}|x_{0})}{p_{\\theta}(x_{0}|x_{1})} \\right] \\\\ \u0026= \\mathbb{E}_{q}\\left[ \\log \\frac{q(x_{T}|x_{0})}{p_{\\theta}(x_{T}) } + \\sum_{t=2}^T \\log \\frac{ q(x_{t-1}|x_{t}, x_{0})}{p_{\\theta}(x_{t-1}|x_{t})} - \\log p_{\\theta}(x_{0}|x_{1}) \\right] \\\\ \u0026= \\underbrace{D_{KL}(q(x_{T}|x_{0})\\| p_{\\theta}(x_{T}))}_{L_{T}} + \\sum_{t=2}^T \\underbrace{D_{KL}(q(x_{t-1}|x_{t}, x_{0})\\| p_{\\theta}(X_{t-1}\\|x_{t}))}_{L_{t-1}} \\underbrace{-\\log p_{\\theta}(x_{0}|x_{1})}_{L_{0}} \\end{aligned} $$ ",
  "wordCount" : "1222",
  "inLanguage": "en",
  "datePublished": "2024-10-21T04:34:23+08:00",
  "dateModified": "2024-10-21T04:34:23+08:00",
  "author":{
    "@type": "Person",
    "name": "Chaohua Wang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://wangchxx.github.io/posts/diffusion_1_ddmp/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "My Notes",
    "logo": {
      "@type": "ImageObject",
      "url": "https://wangchxx.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://wangchxx.github.io/" accesskey="h" title="My Notes (Alt + H)">My Notes</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://wangchxx.github.io/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://wangchxx.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://wangchxx.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://wangchxx.github.io/series/" title="Series">
                    <span>Series</span>
                </a>
            </li>
            <li>
                <a href="https://wangchxx.github.io/categories" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      DL | Diffusion Models 1 - DDMP
    </h1>
    <div class="post-meta"><span title='2024-10-21 04:34:23 +0800 CST'>October 21, 2024</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;Chaohua Wang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#what" aria-label="What?">What?</a></li>
                <li>
                    <a href="#why" aria-label="Why?">Why?</a></li>
                <li>
                    <a href="#how" aria-label="How?">How?</a><ul>
                        
                <li>
                    <a href="#forward-process" aria-label="Forward process">Forward process</a></li>
                <li>
                    <a href="#reverse-process" aria-label="Reverse process">Reverse process</a></li>
                <li>
                    <a href="#algorithm" aria-label="Algorithm">Algorithm</a></li></ul>
                </li>
                <li>
                    <a href="#supplementary" aria-label="Supplementary">Supplementary</a><ul>
                        
                <li>
                    <a href="#langevin-dynamics" aria-label="Langevin dynamics">Langevin dynamics</a></li>
                <li>
                    <a href="#proof-of-conditional-posterior-px_t-1x_tx_0" aria-label="Proof of conditional posterior $p(x_{t-1}|x_t,x_0)$">Proof of conditional posterior $p(x_{t-1}|x_t,x_0)$</a></li>
                <li>
                    <a href="#proof-of-loss-function-l_vlb" aria-label="Proof of Loss function $L_{VLB}$">Proof of Loss function $L_{VLB}$</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="what">What?<a hidden class="anchor" aria-hidden="true" href="#what">#</a></h2>
<p>A diffusion probabilistic model is a parameterized Markov chain that gradually adds noise to the data and then learn to reverse the diffusion process to generate data samples from noise.</p>
<p><img loading="lazy" src="/posts/diffusion_1_ddmp/ddmp_graph.png"></p>
<h2 id="why">Why?<a hidden class="anchor" aria-hidden="true" href="#why">#</a></h2>
<p>Compared with other AI tasks, image generation is harder, since it does not have a standard answer. To solve this issue, GAN and VAE are propsed.</p>
<ul>
<li>
<p>GAN uses another model (discriminator) to decide the quality of generated images.</p>
</li>
<li>
<p>VAE learns how to compress an image into a latent vector $z$ and then learns how to reconstruct the image from $z$. Then for each generated image, there exists a standard answer.GAN is able to generate images with good quality, but its training is unstable. Is there a model that is as powerful as GAN but simpler for training?</p>
</li>
</ul>
<h2 id="how">How?<a hidden class="anchor" aria-hidden="true" href="#how">#</a></h2>
<h3 id="forward-process">Forward process<a hidden class="anchor" aria-hidden="true" href="#forward-process">#</a></h3>
<p>Given a data point sampled from a real data distribution $x_0\sim q(x)$, the forward process is defined by</p>
$$
q(x_t|x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t I),\quad q(x_{1:T}|x_0) = \prod_{t=1}^T q(x_t|x_{t-1}).
$$<p>A nice property of the forward process is that it admits sampling $x_t$ at an arbitrary timestep $t$ in closed form:</p>
$$
\begin{equation}
q(x_t|x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1-\bar{\alpha}_{t})I),
\end{equation}
$$<p>where $\alpha_t := 1-\beta_t$ and $\bar{\alpha}_t:= \prod_{s=0}^t \alpha_s$. To make sure that $q(x_t|x_0)$ is convergent, we need $\bar{\alpha}_t \to C$ as $t\to\infty$. It can be guaranteed by setting $\beta_t\in (0,1)$ as an increasing sequence and therefore $\bar{\alpha}_1>\cdots>\bar{\alpha}_T$.</p>
<h3 id="reverse-process">Reverse process<a hidden class="anchor" aria-hidden="true" href="#reverse-process">#</a></h3>
<p>If we can reverse the above process and sample from $q(x_{t-1}|x_t)$, we will be able to recreate the true sample from a Gaussian noise input $x_T\sim N(0, I)$. Note that if $\beta_t$ is small enough, $q(x_{t-1}|x_t)$ will also be Gaussian (==We will prove it in Diffusion-model-3==). However, we cannot easily estimate $q(x_{x-1}|x_t)$ because it needs to use the entire dataset. So we try to estimate it through a model $p_\theta(x_{t-1}|x_t)$. We set</p>
$$
p_\theta(x_{t-1}|x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t));\quad p_\theta(x_{0:T}) = p(x_T)\prod_{t=1}^T p_\theta(x_{t-1}|x_t).
$$<p>But how to define the loss function? Fitting the mean and variance of added noise from the step $q(x_{t-1}|x_t)$ is unrealistic.</p>
<p><strong>Conditional posterior</strong></p>
<p>It is noteworthy that the reverse conditional probability is tractable when conditioned on $x_0$:</p>
$$
q(x_{t-1}|x_t, x_0) = \mathcal{N}(x_{t-1}; \tilde{\mu}_t(x_t, x_0), \tilde{\beta}_t I),
$$<p>where</p>
$$
\begin{equation}
\tilde{\mu}_t(x_t, x_0) := \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}x_t +\frac{\bar{\alpha}_{t-1}\beta_t}{1-\bar{\alpha}_t}x_0;\quad \tilde{\beta}_t:= \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\beta_t.
\end{equation}
$$<p>See <a href="/posts/diffusion_1_ddmp/#proof_of_conditional_posterior">Proof of conditional posterior</a>.</p>
<p><strong>Loss function</strong></p>
<p>Then we can use the variational lower bound to optimize the negative log-likehood.</p>
$$
\begin{aligned}
-\log p_{\theta}(x_{0}) &\leq -\log p_{\theta}(x_{0}) + D_{KL}(q(x_{1:T}|x_{0})\|p_{\theta}(x_{1:T}|x_{0})) \\
    &= -\log p_{\theta}(x_{0}) + \mathbb{E}_{q}\left[ \log  \frac{q(x_{1:T}|x_{0})}{p_{\theta}(x_{0:T})/p_{\theta}(x_{0})} \right]\\
    &=-\log p_{\theta}(x_{0})  + \mathbb{E}_{q}\left[ \log  \frac{q(x_{1:T}|x_{0})}{p_{\theta}(x_{0:T})} +\log p_{\theta}(x_{0}) \right]\\
    &=\mathbb{E}_{q}\left[ \log  \frac{q(x_{1:T}|x_{0})}{p_{\theta}(x_{0:T})}  \right] := L_{VLB}
\end{aligned}
$$<p>Then we rewrite $L_{VLB}$ in terms of $q(x_{t-1}|x_{t},x_{0})$:</p>
$$
\begin{align}
L_{VLB} &= L_{T} + L_{T-1} + \cdots + L_{0}, \\ 
    \text{where} \; L_{T} & = D_{KL}(q(x_{T}|x_{0})\|p_{\theta}(x_{T})),  \\
	L_{t} & = D_{KL}(q(x_{t}|x_{t+1},x_{0})\| p_{\theta}(x_{t}|x_{t+1})),\; 1\leq t\leq T-1, \\
    L_{0} & = -\log p_{\theta}(x_{0}|x_{1}).
\end{align}
$$<p>See <a href="/posts/diffusion_1_ddmp/#proof_of_loss">Proof of loss</a>. $L_{T}$ is constant because $x_{T}$ is a Gaussian noise. $L_{0}$ is modeled using a separate decoder. $L_{t}$ compares two Gaussian distributions and therefore can be computed in closed form.</p>
<p><strong>Simplification of $L_{t}$</strong></p>
<p>It is known that the KL divergence between two Gaussian distributions $\mathcal{N}(\mu_{p}, \Sigma_{p})$ and $\mathcal{N}(\mu_{q},\Sigma_{q})$ is</p>
$$
D_{KL}(p\|q) = \frac{1}{2} \left[ \log \frac{|\Sigma_{q}|}{|\Sigma_{p}|} + (\mu_{p} -\mu_{q})^T \Sigma_{q}^{-1}(\mu_{q} - \mu_{p}) + Tr(\Sigma_{q}^{-1}\Sigma_{p}) \right] + C.
$$<p>Since the authors set $\Sigma_{\theta}(x_{t}, t) = \sigma_{t}^2 I$, where $\sigma_{t}$ is not learnable. We can simplify $L_{t}$ as</p>
$$
\begin{equation}
L_{t} = \frac{1}{2\|\Sigma_{\theta}(x_{t},t)\|_{2}^2} \|\tilde{\mu}(x_{t},x_{0}) - \mu_{\theta}(x_{t},t)\|^2 + C.
\end{equation}
$$<p>We can expand the above loss by reparameterizing $q(x_t|x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1-\bar{\alpha})I)$ as $x_{t}(x_{0}, \epsilon) = \sqrt{ \bar{\alpha}_{t} }x_{0} + \sqrt{ 1-\bar{\alpha}_{t} }\epsilon$ for $\epsilon\sim\mathcal{N}(0, I)$:</p>
$$
\begin{aligned}
\tilde{\mu}_{t} &= \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}x_t +\frac{\bar{\alpha}_{t-1}\beta_t}{1-\bar{\alpha}_t}{\color{green}x_0} \\
    &=\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}x_t +\frac{\bar{\alpha}_{t-1}\beta_t}{1-\bar{\alpha}_t} {\color{green} \frac{1}{\sqrt{ \bar{\alpha}_{t} }}(x_{t} - \sqrt{ 1-\bar{\alpha}_{t} }\epsilon)} \\
    &=\frac{1}{\sqrt{ \alpha_{t} }}\left( x_{t} - \frac{1-\alpha_{t}}{\sqrt{ 1-\bar{\alpha}_{t} }} \epsilon \right)
\end{aligned}
$$<p>Instead of approximating $\tilde{\mu}_{t}$ by $\mu_{\theta}$ directly, we can also estimate the noise $\epsilon$ using $\epsilon_{\theta}(x_{t}, t)$ (like ResNet) by setting</p>
$$
\begin{align}
\mu_{\theta}(x_{t}, t) = \tilde{\mu}_{t}(x_{t}, t) &= \frac{1}{\sqrt{ \alpha_{t} }}\left( x_{t} - \frac{1-\alpha_{t}}{\sqrt{ 1-\bar{\alpha}_{t} }} \epsilon_{\theta}(x_{t}, t) \right).\\
\end{align}
$$<p>Therefore, we can rewrite the loss function $L_{t}$ as</p>
$$
\begin{align}
L_{t} &= \mathbb{E}_{x_{0}, \epsilon} \left[\frac{(1-\alpha_{t})^2}{2 \alpha_{t}(1-\bar{\alpha}_{t})\|\Sigma_{\theta}(x_{t},t)\|_{2}^2} \| \epsilon - \epsilon_{\theta}(x_{t},t)\|^2 \right] + C \\
 & = \mathbb{E}_{x_{0}, \epsilon} \left[\frac{(1-\alpha_{t})^2}{2 \alpha_{t}(1-\bar{\alpha}_{t})\|\Sigma_{\theta}(x_{t},t)\|_{2}^2} \| \epsilon - \epsilon_{\theta}({\color{green}\sqrt{ \bar{\alpha}_{t} }x_{0} + \sqrt{ 1-\bar{\alpha}_{t} }\epsilon},t)\|^2 \right] + C 
\end{align}
$$<h3 id="algorithm">Algorithm<a hidden class="anchor" aria-hidden="true" href="#algorithm">#</a></h3>
<p>Empirically, the authors found that training the diffusion model works better with a simplified objective that ignores the weighting term:</p>
$$
L_{t}^{simple} = \mathbb{E}_{x_{0}, \epsilon} \left[\| \epsilon - \epsilon_{\theta}(\sqrt{ \bar{\alpha}_{t} }x_{0} + \sqrt{ 1-\bar{\alpha}_{t} }\epsilon,t)\|^2 \right].
$$<p><img loading="lazy" src="/posts/diffusion_1_ddmp/ddmp_algorithm.png"></p>
<h2 id="supplementary">Supplementary<a hidden class="anchor" aria-hidden="true" href="#supplementary">#</a></h2>
<h3 id="langevin-dynamics">Langevin dynamics<a hidden class="anchor" aria-hidden="true" href="#langevin-dynamics">#</a></h3>
<p>Langevin dynamics is a concept from physics, developed for statistically modeling molecular systems. Combined with stochastic gradient descent, stochastic gradient Langevin dynamics can produce samples from a probability distribution $p(x)$ using only gradients $\nabla_{x} \log p(x)$ in a Markov chain of updates:
</p>
$$
x_{t} = x_{t-1} + \frac{\delta}{2}\nabla_{x} \log p(x_{t-1}) + \sqrt{ \delta }\epsilon_{t},\quad \epsilon_{t}\sim \mathcal{N}(0,I),
$$<p>
where $\delta$ is the step size. When $T\to \infty$, $\epsilon\to 0$, $x_{T}\sim p(x)$.</p>
<p>We can see that we only need to know the gradients $\nabla_{x} \log p(x)$ (score function) to sample data from $p(x)$.</p>
<p>Let $(x, \tilde{x})$ be a pair of clean and corrupted data. The idea of denoising score matching is to estimate the score function of the noise-corrupted data distribution $q_{\sigma}(\tilde{x})$, and the objective is shown to be equivalent to
</p>
$$
\mathbb{E}_{q_{\sigma}(\tilde{x}|x) p(x)} [\|s(\tilde{x}, \theta) - \nabla_{x}\log q_{\sigma}(\tilde{x}|x)\|_{2}^2].
$$<p>
The schedule of increasing noise levels resembles the forward diffusion process $q(x_{t}|x_{0})$.  If we use the diffusion process annotation, the score approximates $s_{\theta}(x_{t}, t)\approx \nabla_{x_{t}}q(x_{t}|x_{0})$. Note that given a Gaussian distribution $x\sim\mathcal{N}(\mu,\sigma^2I)$, its score function is
</p>
$$
\nabla_{x} \log p(x) = - \frac{x-\mu}{\sigma^2} = - \frac{\epsilon}{\sigma}, \quad \epsilon\sim \mathcal{N}(0,I).
$$<p>
Recall that $q(x_{t}|x_{0})\sim \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1-\bar{\alpha})I)$ and therefore,
</p>
$$
s_{\theta}(x_{t},t) \approx \nabla_{x_{t}}\log q(x_{t}) = \mathbb{E}_{q(x_{0})}[\nabla_{x_{t}}q(x_{t}|x_{0})] = - \frac{\epsilon}{\sqrt{ 1-\bar{\alpha}_{t} }},
$$<p>
which is equivalent to the loss function $L_{t}$ in DDPM.</p>
<h3 id="proof-of-conditional-posterior-px_t-1x_tx_0">Proof of conditional posterior $p(x_{t-1}|x_t,x_0)$<a hidden class="anchor" aria-hidden="true" href="#proof-of-conditional-posterior-px_t-1x_tx_0">#</a></h3>
<p>Using Bayes&rsquo; rule, we have <span id = "proof_of_conditional_posterior">
</p>
$$
\begin{aligned}
q(x_{t-1}|x_{t}, x_{0}) &= q(x_{t}|x_{t}, x_{0}) \frac{q(x_{t-1}|x_{0})}{q(x_{t}|x_{0})}  \\
 & \propto \exp\left( -\frac{1}{2}\left(  \frac{(x_{t}- \sqrt{ \alpha_{t}  }x_{t-1})^2}{\beta_{t}}  +  \frac{(x_{t-1}- \sqrt{ \bar{\alpha}_{t-1}  }x_{0})^2}{1-\bar{\alpha}_{t-1}} - \frac{(x_{t}- \sqrt{ \bar{\alpha}_{t}  }x_{0})^2}{1-\bar{\alpha}_{t}}   \right) \right) \\
 & \propto  \exp\left( -\frac{1}{2}\left(  \frac{- 2\sqrt{ \alpha_{t}} x_{t}{\color{blue}x_{t-1}} + \alpha_{t} \color{red}x_{t-1}^2}{\beta_{t}}  +  \frac{ {\color{red}x_{t-1}^2}- 2\sqrt{ \bar{\alpha}_{t-1}  }x_{0}{\color{blue}{x_{t-1}}}  }{1-\bar{\alpha}_{t-1}} \right) \right) \\ 
 & \exp\left( -\frac{1}{2} \left(  {\color{red} \left( \frac{\alpha_{t}}{\beta_{t}} + \frac{1}{1-\bar{\alpha}_{t-1}} \right)x_{t-1}^2} - {\color{blue}\left( \frac{2\sqrt{ \alpha_{t} }}{\beta_{t}} x_{t} +  \frac{2\sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha}_{t-1}}  \right) x_{t-1}} \right) \right)
\end{aligned}
$$<p>
By completing the square, we have
</p>
$$
\begin{aligned}
\tilde{\beta}_{t} &= \frac{1}{\left( \frac{\alpha_{t}}{\beta_{t}} + \frac{1}{1-\bar{\alpha}_{t-1}} \right)} = \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_{t}}\beta_{t},  \\
\tilde{\mu}_{t} &= \left( \frac{2\sqrt{ \alpha_{t} }}{\beta_{t}} x_{t} +  \frac{2\sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha}_{t-1}}  \right) / \tilde{\beta}_{t} = \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}x_t +\frac{\bar{\alpha}_{t-1}\beta_t}{1-\bar{\alpha}_t}x_0.
\end{aligned}
$$<h3 id="proof-of-loss-function-l_vlb">Proof of Loss function $L_{VLB}$<a hidden class="anchor" aria-hidden="true" href="#proof-of-loss-function-l_vlb">#</a></h3>
<span id = "proof_of_loss">
$$
\begin{aligned}
L_{VLB} &= \mathbb{E}_{q}\left[ \log  \frac{q(x_{1:T}|x_{0})}{p_{\theta}(x_{0:T})}  \right]  \\
    &= \mathbb{E}_{q}\left[ \log  \frac{\prod_{t=1}^Tq(x_{t}|x_{t-1})}{p_{\theta}(x_{T})\prod_{t=1}^T p_{\theta}(x_{t-1}|x_{t})}  \right]  \\
    &= \mathbb{E}_{q}\left[  -\log p_{\theta}(x_{T}) + \sum_{t=2}^T \log  \frac{ q(x_{t}|x_{t-1})}{p_{\theta}(x_{t-1}|x_{t})} + \log \frac{q(x_{1}|x_{0})}{p_{\theta}(x_{0}|x_{1})}  \right] \\
    &= \mathbb{E}_{q}\left[  -\log p_{\theta}(x_{T}) + \sum_{t=2}^T \log  \frac{ q(x_{t}|x_{t-1}, {\color{red}{x_{0}}})}{p_{\theta}(x_{t-1}|x_{t})} + \log \frac{q(x_{1}|x_{0})}{p_{\theta}(x_{0}|x_{1})}  \right] \\
    &= \mathbb{E}_{q}\left[  -\log p_{\theta}(x_{T}) + \sum_{t=2}^T \log  \frac{ q(x_{t-1}|x_{t}, x_{0})}{p_{\theta}(x_{t-1}|x_{t})} \cdot \frac{q(x_{t}|x_{0})}{q(x_{t-1}|x_{0})} + \log \frac{q(x_{1}|x_{0})}{p_{\theta}(x_{0}|x_{1})}  \right] \\
    &= \mathbb{E}_{q}\left[  -\log p_{\theta}(x_{T}) + \sum_{t=2}^T \log  \frac{ q(x_{t-1}|x_{t}, x_{0})}{p_{\theta}(x_{t-1}|x_{t})} + \sum_{t=2}^T \log \frac{q(x_{t}|x_{0})}{q(x_{t-1}|x_{0})} + \log \frac{q(x_{1}|x_{0})}{p_{\theta}(x_{0}|x_{1})}  \right] \\
    &=  \mathbb{E}_{q}\left[  -\log p_{\theta}(x_{T}) + \sum_{t=2}^T \log  \frac{ q(x_{t-1}|x_{t}, x_{0})}{p_{\theta}(x_{t-1}|x_{t})} +  \log \frac{q(x_{T}|x_{0})}{q(x_{1}|x_{0})} + \log \frac{q(x_{1}|x_{0})}{p_{\theta}(x_{0}|x_{1})}  \right] \\
    &=  \mathbb{E}_{q}\left[ \log \frac{q(x_{T}|x_{0})}{p_{\theta}(x_{T}) }  + \sum_{t=2}^T \log  \frac{ q(x_{t-1}|x_{t}, x_{0})}{p_{\theta}(x_{t-1}|x_{t})}  - \log p_{\theta}(x_{0}|x_{1})  \right] \\
    &= \underbrace{D_{KL}(q(x_{T}|x_{0})\| p_{\theta}(x_{T}))}_{L_{T}} + \sum_{t=2}^T \underbrace{D_{KL}(q(x_{t-1}|x_{t}, x_{0})\| p_{\theta}(X_{t-1}\|x_{t}))}_{L_{t-1}}  \underbrace{-\log p_{\theta}(x_{0}|x_{1})}_{L_{0}} 
\end{aligned}
$$


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="prev" href="https://wangchxx.github.io/posts/diffusion_2_preliminary_sde/">
    <span class="title">« Prev</span>
    <br>
    <span>DL | Diffusion Models 2 - Preliminary ODE and SDE</span>
  </a>
  <a class="next" href="https://wangchxx.github.io/posts/rl/rl_09_mcts/">
    <span class="title">Next »</span>
    <br>
    <span>RL | Multiplayer Monte Carlo Tree Search</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="https://wangchxx.github.io/">My Notes</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
