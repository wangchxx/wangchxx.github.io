<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta property="og:title" content="Bayesian Statistics| Gaussian Process Priors (3)" />
<meta property="og:description" content="In GP(1) and GP(2), we studied the RKSH and consistency rate of GP priors. In this sectin we are going to consider the smoothness of the target function and see how the smoothness level impacts the consistency rates.
1. Introduction Suppose that we want to estimate a density function $p_0 \in C^\beta[0,1]$, where $C^\beta[0,1]$ denotes the H$\mathrm{&quot;o}$lder space of order $\beta$. By Assouad’s method it can shown that no estimator can achieve better rates than $n^{-\beta/(2\beta&#43;1)}$ uniformly, in terms of the distance $d(p_0, p) = ||p_0 - p||_1$." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://wangchxx.github.io/posts/bayes/bayes_7_gp3/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-08-05T00:01:41+02:00" />
<meta property="article:modified_time" content="2021-08-05T00:01:41+02:00" />
<meta property="og:see_also" content="https://wangchxx.github.io/posts/bayes/bayes_6_gp2/" /><meta property="og:see_also" content="https://wangchxx.github.io/posts/bayes/bayes_4_gp1/" /><meta property="og:see_also" content="https://wangchxx.github.io/posts/bayes/bayes_5_contraction/" /><meta property="og:see_also" content="https://wangchxx.github.io/posts/bayes/bayes_3_dirichlet/" /><meta property="og:see_also" content="https://wangchxx.github.io/posts/bayes/bayes_2_bvm/" />


  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Bayesian Statistics| Gaussian Process Priors (3)"/>
<meta name="twitter:description" content="In GP(1) and GP(2), we studied the RKSH and consistency rate of GP priors. In this sectin we are going to consider the smoothness of the target function and see how the smoothness level impacts the consistency rates.
1. Introduction Suppose that we want to estimate a density function $p_0 \in C^\beta[0,1]$, where $C^\beta[0,1]$ denotes the H$\mathrm{&quot;o}$lder space of order $\beta$. By Assouad’s method it can shown that no estimator can achieve better rates than $n^{-\beta/(2\beta&#43;1)}$ uniformly, in terms of the distance $d(p_0, p) = ||p_0 - p||_1$."/>

  
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#262d33">
  <title>
    
    My Math Notes - Bayesian Statistics| Gaussian Process Priors (3)
    
  </title>
  
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;500;600;700&display=swap"
    rel="stylesheet">
  <link rel="stylesheet" href="https://unpkg.com/normalize.css">
  <link rel="stylesheet" type="text/css" media="screen" href="/css/main.css" />
  <link rel="stylesheet" type="text/css" media="screen" href="/css/md.css" />
  <link rel="stylesheet" type="text/css" media="screen" href="/css/syntax.css" />
  <script src="/js/main.js"></script>
</head>
<script>
  try {
    if (!('theme' in localStorage)) {
      localStorage.theme = window.matchMedia('(prefer-color-scheme: dark)').matches ? 'dark' : 'light';
    }
    document.querySelector('html').classList.add(localStorage.theme);
  } catch (e) {
    console.error(e);
  }
</script>
<body>
  <header>
  <h1 class="row gap-1">
    <div id="theme-switcher" class="btn lg-1"></div>
    My Math Notes
  </h1>
  <nav class="row gap-1">
  
    <a href="/">Home</a>
  
    <a href="/categories">Categories</a>
  
    <a href="/series">Series</a>
  
    <a href="/about">About</a>
  
  </nav>
  <hr>
</header>
  
  
<main>
	<h1>Bayesian Statistics| Gaussian Process Priors (3)</h1>
	<div class="sm-1 mtb-1">
		Posted at &mdash; Aug 5, 2021
		
	</div>
	<p></p>
	<article class="md">
		<p>In GP(1) and GP(2), we studied the RKSH and consistency rate of GP priors. In this sectin we are going to consider the smoothness of the target function and see how the smoothness level impacts the consistency rates.</p>
<h2 id="1-introduction">1. Introduction</h2>
<p>Suppose that we want to estimate a density function $p_0 \in C^\beta[0,1]$, where $C^\beta[0,1]$ denotes the H$\mathrm{&quot;o}$lder space of order $\beta$. By Assouad’s method it can shown that no estimator can achieve better rates than $n^{-\beta/(2\beta+1)}$ uniformly, in terms of the distance $d(p_0, p) = ||p_0 - p||_1$. It has been long known that some estimators can achieve this rate given known smoothness level $\beta$, for instance, kernel estimators.</p>
<p>In general the smoothness parameter is unknown. If we choose a parameter $\beta'&gt;\beta$, then we lose in terms of the consistency rate. On the other hand, if we choose a family of functions with smoothness level $\beta'&lt;\beta$, then the model is misspecified. In this case, consistency cannot be guaranteed. Therefore, we intend to find an estimator that achieves the optimal minimax rate without knowing $\beta$, which is called <em>adaption</em>.</p>
<h2 id="2-rkhs-of-bm-and-smoothness">2. RKHS of BM and Smoothness</h2>
<p>Let review the contraction rate of GP priors</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p><img src="/img_bayes_GP/GPrate_1.PNG" alt="GP contraction">
It implies that the optimal consistency rate for GP priors cannot be better than $n^{-1/2}$ when $w_0\in \bar{\mathbb{H}}$. To estimate the density function, we need a RKHS containing continuous fucntions, so that Brownian motion is of interest.</p>
<dl>
<dt>Lemma (RKSH of BM)</dt>
<dd>The RKSH of BM is the family of fuctions in $B^1[0,1]$  vanishing at zero, where $B^k[0,1]$ is the Sobolev space of all functions $f\in L^2[0,1]$ that are $k-1$ times differentiable with $f^{(k-1)}$ absolutely continuous with $f^{(k)}\in L^2[0,1]$, equipped with the inner product
$$
&lt;f,g&gt;_{\mathbb{H}} = \int_0^1 f' g' d\mu.
$$
proof</dd>
<dd>The covariance kernel of BM is $r(s,t) = s\wedge t$. The RKHS is the closed linear span of functions $t\mapsto s\wedge t$ as $s$ runs through $[0,1]$, unnder the inner product given by
$$
&lt;s_1\wedge \cdot, s_2\wedge\cdot&gt;_{\mathbb{H}} = s_1\wedge s_2 = \int (s_1\wedge t)' (s_2\wedge t)' dt.
$$
Thus the RKHS contains every function that vanishes at 0, continuous, and piecewise linear on any partition of $[0,1]$. The derivatives of these functions are piecewise constant, and the set of piecewise constant function is dense in $L^2[0,1]$.</dd>
</dl>
<p>$\Box$</p>
<p>Without proof, we state that, if $w_0\in C^\beta[0,1]$ for some $\beta\in(0,1]$, the contraction rate of BM prior is
$$
n^{-\frac{\beta\wedge 1/2}{2}}.
$$
The optimal minimax rate can only be obtained for functions $p_0\in C^{1/2}[0,1]$. For any $\beta\neq 1/2$, the contraction rate is at most $n^{-1/4}$, which is caused by the rough paths of BM. But the BM is a good building block for smoother function spaces.</p>
<ul>
<li>Integrated BM. The $k$-fold integration of BM $I_{0+}^k B = I_{0+} I_{0+}^{k-1}B$, where $(I_{0+} f)(t) = \int_0^t f(s) ds $. The RKHS of $I_{0+}^k B$ is $B^{k+1}[0,1]$, with inner product
$$
&lt;f,g&gt;_{\mathbb{H}} = \int_0^1 f^{(k+1)} (s) g^{(k+1)} (s) ds.
$$</li>
</ul>
<p>The k-fold integrated BM priors achieve contraction rates $n^{-\frac{\beta\wedge k + 1/2}{2k+2}}$, where the optimal rate is obtained at $\beta = k + 1/2$ only. For $\beta\geq k+1/2$, the performance does not improve for increasing $\beta$.</p>
<h2 id="3-adaptive-gp-priors">3. Adaptive GP Priors</h2>
<p>The GP priors discussed so far possess itself a certain regularity, and are optimal iff this matches the regularity of the target function. To obtain a prior that is adaptive for unknown $\beta&gt;0$, there are two popular methods:</p>
<ol>
<li>Hierachical prior, impose a prior on the smoothness prameter $\beta$, which is also known as <em>mixtures of GP</em>.</li>
<li>Rescaling, $W^a = (W_{ct}:t \in [0,1])$.</li>
</ol>
<p>Here, we shall discuss rescaling only. The rescaling has the purpose of changing the appearance of the sample paths, making our prior reflect the true function better. Scaling factor $c&gt;1$ shrinks the sample paths $t\mapsto W_t$ on a long interval $W_{[0,ct]}$ to the interval $[0,1]$, which roughens the sample paths by incorporating the randomness of a longer period. Conversely, factor $c&lt;1$ stretchs the sample paths to a shorter interval $[0,ct]$, which smooths the sample paths.</p>
<dl>
<dt>Def (Self-similar)</dt>
<dd>A SP $W$ is called <em>self-similar</em> of order $\alpha$ if $(W_{ct}: t\in[0,1])$ and $(c^\alpha W_t: t\in [0,1])$ are equal in distribution.</dd>
<dt>Lemma (RKHS of rescaled GP)</dt>
<dd>The RKHS $\mathbb{H}^c$ of the rescaled process $W^c$ corresponding to a self-similar process $W$ of order $\alpha$ is a RKHS of $W$, equipped with the norm $||h||_{\mathbb{H}^c} = c^{-\alpha}||h||_{\mathbb{H}}$ instead.</dd>
</dl>
<p>Without proof we state that the optimal contraction rate of rescaled GP corresponding to a self-similar process $W$ of order $\alpha$ is
$$
n^{-\frac{2+r}{(4+ 4r + rs)}}, \quad \text{ by setting } c_n = n^{\frac{s-r}{4\alpha + 4r\alpha + rs\alpha}},
$$
where $r,s&gt;0$ are some constants s.t.
$$
\psi_0(\epsilon) \asymp \epsilon^{-r} ,\quad \inf \{ ||h||_{\mathbb{H}}: ||h-w_0||\leq \epsilon \} \asymp \epsilon^{-s}.
$$
Note that the optimal contraction rate does not depends on the parameter $\alpha$. BM is self-similar of order $1/2$, and thus the k-fold integrated BM is self-similar of order $1/2 + k$. If $w_0 \in C^\beta [0,1]$ with $\beta\leq k+1$. The rescaled k-fold integraed BM priors yield the minimax rate $n^{-\beta/(2\beta + 1)}$ by setting appropriate scaling factor $c_n$.</p>
<h2 id="references">References</h2>
<ul>
<li>
<p>[1] van der Vaart, A. W., &amp; van Zanten, J. H. (2008). Reproducing kernel Hilbert spaces of Gaussian priors.</p>
</li>
<li>
<p>[2] Ghosal, S., &amp; Van der Vaart, A. (2017). Fundamentals of nonparametric Bayesian inference.</p>
</li>
<li>
<p>[3] Vaart, A. V. D., &amp; Zanten, H. V. (2007). Bayesian inference with rescaled Gaussian process priors.</p>
</li>
<li>
<p>[4] Belitser, E., &amp; Ghosal, S. (2003). Adaptive Bayesian inference on the mean of an infinite-dimensional normal distribution. The Annals of Statistics, 31(2), 536–559.</p>
</li>
<li>
<p>[5] Tsybakov, A. B. (2009). Introduction to nonparametric estimation. Springer.</p>
</li>
</ul>

	</article>
</main>
	
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css"
  integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.js"
  integrity="sha384-YNHdsYkH6gMx9y3mRkmcJ2mFUjTd0qNQQvY9VYZgQd7DcN7env35GzlmFaZ23JGp" crossorigin="anonymous"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/contrib/auto-render.min.js"
  integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous"></script>

<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      
      
      delimiters: [
        { left: '$$', right: '$$', display: true },
        { left: '$', right: '$', display: false },
        { left: '\\(', right: '\\)', display: false },
        { left: '\\[', right: '\\]', display: true },
        
      ],
      
      throwOnError: false
    });
  });
</script>
	

	

	



  <footer class="row row-mob al-c-mob col-rev-mob sm-2-mob  jc-bt mtb-2">
  <p>
    © Copyright notice |
    <a href="https://github.com/mivinci/hugo-theme-minima" target="_blank" rel="noopener noreferrer">Minima</a> theme on
    <a href="https://gohugo.io" target="_blank" rel="noopener noreferrer">Hugo</a>
  </p>
  <p class="row gap-0_5">
    
      <a class="icon" href="https://github.com/wangchxx" title="github">
      
        <svg fill="#63636f" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
      
      </a>
    
  </p>
</footer>
</body>
</html>