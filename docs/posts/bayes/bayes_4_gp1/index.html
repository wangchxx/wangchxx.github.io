<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Bayesian Statistics| Gaussian Process Priors (1) | My Notes</title>
<meta name="keywords" content="">
<meta name="description" content="
In the previous chapters, we introduced the Dirichlet Process (DP) prior, which is primarily used as a prior on measure spaces. In this chapter, we will introduce the Gaussian Process (GP), which can be used as a prior on function spaces. Consider the scenario where we have sample pairs $(X_i,Y_i),i\leq n$. We are interested in studying the relationship between the inputs $X_i$ and the outputs $Y_i$.  A common model for such a relationship is
">
<meta name="author" content="Chaohua Wang">
<link rel="canonical" href="https://wangchxx.github.io/posts/bayes/bayes_4_gp1/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.14b508198d6c32523f8895e6c6606da34de25e588fe390ef44ad07a0cc7dad33.css" integrity="sha256-FLUIGY1sMlI/iJXmxmBto03iXliP45DvRK0HoMx9rTM=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://wangchxx.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://wangchxx.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://wangchxx.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://wangchxx.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://wangchxx.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://wangchxx.github.io/posts/bayes/bayes_4_gp1/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: '\\[', right: '\\]', display: true},   
        {left: '$$', right: '$$', display: true},     
        {left: '$', right: '$', display: false},  
      ],
      throwOnError : false
    });
  });
</script>



<meta property="og:title" content="Bayesian Statistics| Gaussian Process Priors (1)">
<meta property="og:description" content="
In the previous chapters, we introduced the Dirichlet Process (DP) prior, which is primarily used as a prior on measure spaces. In this chapter, we will introduce the Gaussian Process (GP), which can be used as a prior on function spaces. Consider the scenario where we have sample pairs $(X_i,Y_i),i\leq n$. We are interested in studying the relationship between the inputs $X_i$ and the outputs $Y_i$.  A common model for such a relationship is
">
<meta property="og:type" content="article">
<meta property="og:url" content="https://wangchxx.github.io/posts/bayes/bayes_4_gp1/"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2021-07-21T10:52:59+02:00">
<meta property="article:modified_time" content="2021-07-21T10:52:59+02:00">


<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Bayesian Statistics| Gaussian Process Priors (1)">
<meta name="twitter:description" content="
In the previous chapters, we introduced the Dirichlet Process (DP) prior, which is primarily used as a prior on measure spaces. In this chapter, we will introduce the Gaussian Process (GP), which can be used as a prior on function spaces. Consider the scenario where we have sample pairs $(X_i,Y_i),i\leq n$. We are interested in studying the relationship between the inputs $X_i$ and the outputs $Y_i$.  A common model for such a relationship is
">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://wangchxx.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Bayesian Statistics| Gaussian Process Priors (1)",
      "item": "https://wangchxx.github.io/posts/bayes/bayes_4_gp1/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Bayesian Statistics| Gaussian Process Priors (1)",
  "name": "Bayesian Statistics| Gaussian Process Priors (1)",
  "description": " In the previous chapters, we introduced the Dirichlet Process (DP) prior, which is primarily used as a prior on measure spaces. In this chapter, we will introduce the Gaussian Process (GP), which can be used as a prior on function spaces. Consider the scenario where we have sample pairs $(X_i,Y_i),i\\leq n$. We are interested in studying the relationship between the inputs $X_i$ and the outputs $Y_i$. A common model for such a relationship is ",
  "keywords": [
    
  ],
  "articleBody": " In the previous chapters, we introduced the Dirichlet Process (DP) prior, which is primarily used as a prior on measure spaces. In this chapter, we will introduce the Gaussian Process (GP), which can be used as a prior on function spaces. Consider the scenario where we have sample pairs $(X_i,Y_i),i\\leq n$. We are interested in studying the relationship between the inputs $X_i$ and the outputs $Y_i$. A common model for such a relationship is $$Y = \\beta X + \\epsilon.$$In this case, we are looking to estimate the parameter $\\beta$. However, we are considering a more generalized model by replacing the linear function with an unknown function $f(X_{i})$, as: $$Y_i = f(X_i) + \\epsilon_i,$$where $f$ is an unknown function. The goal is to estimate the function $f$, which is an infinite-dimensional model because $f$ represents a function defined over the continuous input space. Gaussian process regression assign $f$ a prior distribution $\\Pi$, and this prior is specifically a Gaussian Process.\n1. Gaussian Process Gaussian Process (GP) can be defined through its finite-dimensional distributions (FDDs).\nDefinition (Gaussian process) the map $t\\mapsto W_t(\\omega)$ is called the sample path of of $W$. Sample paths are functions from $T$ to $\\mathbb{R}$, so the process can be viewed as a map $W:\\Omega \\to \\mathbb{B}$, where $\\mathbb{B}$ is a function space, e.g. the space of continuous functions on $T$.\nThe problem with defining a Gaussian Process solely by its finite-dimensional distributions is that sample paths (i.e., the realizations of the process) may not exhibit the desired properties. For example, a Gaussian Process with a particular kernel might have sample paths that are not continuous, even though the FDDs at any finite set of points may still define a valid Gaussian distribution. To resolve this issue, we seek to find a version $\\tilde{W}$ of the process $W$ s.t. the sample paths $\\tilde{W}$ possess the desired properties. For instance, if we need a space of continuous functions on $T$, we may apply the following theorem\nA more abstract and general formulation of a Gaussian process is related to the dual space of a Banach space. Let $\\mathbb{B}$ be a Banach space. The dual space $\\mathbb{B}^*$ is the space of continuous linear functionals on $\\mathbb{B}$, i.e., the set of all linear maps from $\\mathbb{B}$ to the scalar field.\nDefinition (Gaussian random element) In this framework, the Gaussian Process can be viewed as a random element in the dual space $\\mathbb{B}^*$∗, where the process is defined in terms of the behavior of random variables indexed by elements of a Banach space.\nWhat is the relation between the above two definition of GP？With the second definition we can always construct a Gaussian stochastic process by $(b^{\\*}(W):b^{\\*}\\in T)$, which are jointly normally distributed, for any subset $T\\subset \\mathbb{B}^*$. Additionally，if the sample paths $t\\mapsto W_t$ of the stochastic process $W = (W_t:t\\in T)$ belong to a Banach process $\\mathbb{B}$ of functions $z:T\\to \\mathbb{R}$, then under some conditions the process will be a Gaussian random element. More specifically, the sample paths $t\\mapsto W_t$ belonging to a Banach space means that the process must satisfy certain regularity conditions on the covariance structure and continuity of the sample paths.\n2. Reproducing Kernel Hilbert Space Every Gaussian process is naturally associated with a Hilbert space, determined by its covariance function. For a GP $W = (W_t: t\\in T)$, let $\\overline{lin}(W)$ be the closure of the set of all linear combinations $\\sum_i \\alpha_i W_{t_i}$ in the $L^2$-space of square-integrable variables. Then the space $\\overline{lin}(W)$ is a Hilbert space, with inner product $\u003c f,g\u003e = E f\\bar{g}$, called the first order chaos of $W$.\nDefinition (RKHS, 1) It can be verified that $\\mathbb{H}$ is a Hilbert space.\nLemma (Properties of RKHS) A Gaussian random element in a separable Banach space also comes with a RKHS. First we define the map $S:\\mathbb{B}^*\\to \\mathbb{B}$ by\n$$Sb^* = E[b^*(W)W],$$where the right side is the Pettis integral.\nDefinition (RKHS, 2) The relationship between the two definitions is\n$$r(s,t) = E W_s W_t = E[\\pi_s(W) \\pi_t(W)] = \\langle S\\pi_s, S\\pi_t \\rangle_{\\mathbb H},$$ where $\\pi_t: b\\mapsto b(t)$ are elements in $\\mathbb B^*$.\n3. Small Ball Probability As a Bayesian, we are always interested in the posterior consistency. Here we give some lemmas which are useful to study the posterior consistency of Gaussian process priors.\nLemma (Borell’s) Let $\\Phi$ be the CDF of the standard normal. The additional small ball $\\epsilon\\mathbb B_1$ creates an $\\epsilon$-cushion around $M\\mathbb{B}_1$. This lemma suggests that if we want to use GP prior to estimate a function, we must ensure that the true function is contained in the closure of RKHS.\nLemma (Decentered) Lemma (Small ball) 4. Posterior Contraction Before discussing the posterior contraction of GP priors, we need to introduce some theoretical concepts from infinite-dimensional Bayes theory. This will be a lengthy section, so I will dedicate a separate chapter to it. After that, we will return to discuss the case of GP priors.\nReferences [1] van der Vaart, A. W., \u0026 van Zanten, J. H. (2008). Reproducing kernel Hilbert spaces of Gaussian priors.\n[2] Ghosal, S., \u0026 Van der Vaart, A. (2017). Fundamentals of nonparametric Bayesian inference.\n",
  "wordCount" : "848",
  "inLanguage": "en",
  "datePublished": "2021-07-21T10:52:59+02:00",
  "dateModified": "2021-07-21T10:52:59+02:00",
  "author":{
    "@type": "Person",
    "name": "Chaohua Wang"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://wangchxx.github.io/posts/bayes/bayes_4_gp1/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "My Notes",
    "logo": {
      "@type": "ImageObject",
      "url": "https://wangchxx.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://wangchxx.github.io/" accesskey="h" title="My Notes (Alt + H)">My Notes</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://wangchxx.github.io/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://wangchxx.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://wangchxx.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://wangchxx.github.io/series/" title="Series">
                    <span>Series</span>
                </a>
            </li>
            <li>
                <a href="https://wangchxx.github.io/categories" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Bayesian Statistics| Gaussian Process Priors (1)
    </h1>
    <div class="post-meta"><span title='2021-07-21 10:52:59 +0200 +0200'>July 21, 2021</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Chaohua Wang

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#1-gaussian-process" aria-label="1. Gaussian Process">1. Gaussian Process</a></li>
                <li>
                    <a href="#2-reproducing-kernel-hilbert-space" aria-label="2. Reproducing Kernel Hilbert Space">2. Reproducing Kernel Hilbert Space</a></li>
                <li>
                    <a href="#3-small-ball-probability" aria-label="3. Small Ball Probability">3. Small Ball Probability</a></li>
                <li>
                    <a href="#4-posterior-contraction" aria-label="4. Posterior Contraction">4. Posterior Contraction</a></li>
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><!-- # Bayesian Statistics| Gaussian Process Priors (1) -->
<p>In the previous chapters, we introduced the <strong>Dirichlet Process (DP) prior</strong>, which is primarily used as a prior on measure spaces. In this chapter, we will introduce the <strong>Gaussian Process (GP)</strong>, which can be used as a prior on function spaces. Consider the scenario where we have sample pairs $(X_i,Y_i),i\leq n$. We are interested in studying the relationship between the inputs $X_i$ and the outputs $Y_i$.  A common model for such a relationship is
</p>
$$Y = \beta X  + \epsilon.$$<p>In this case, we are looking to estimate the parameter $\beta$. However, we are considering a more generalized model by replacing the linear function with an unknown function $f(X_{i})$, as:
</p>
$$Y_i = f(X_i) + \epsilon_i,$$<p>where $f$ is an unknown function. The goal is to estimate the function $f$, which is an <strong>infinite-dimensional model</strong> because $f$ represents a function defined over the continuous input space. Gaussian process regression assign $f$ a prior distribution $\Pi$, and this prior is specifically a <strong>Gaussian Process</strong>.</p>
<h2 id="1-gaussian-process">1. Gaussian Process<a hidden class="anchor" aria-hidden="true" href="#1-gaussian-process">#</a></h2>
<p><strong>Gaussian Process (GP)</strong> can be defined through its <strong>finite-dimensional distributions (FDDs)</strong>.</p>
<dl>
<dt>Definition (Gaussian process)</dt>
<dd><img alt="GP_def_1" loading="lazy" src="/img_bayes_GP/GP_1.PNG"></dd>
</dl>
<p>the map $t\mapsto W_t(\omega)$ is called the sample path of of $W$. Sample paths are functions from $T$ to $\mathbb{R}$, so the process can be viewed as a map $W:\Omega \to \mathbb{B}$, where $\mathbb{B}$ is a function space, e.g. the space of continuous functions on $T$.</p>
<p>The problem with defining a Gaussian Process solely by its finite-dimensional distributions is that <strong>sample paths</strong> (i.e., the realizations of the process) may not exhibit the desired properties. For example, a Gaussian Process with a particular kernel might have <strong>sample paths</strong> that are not continuous, even though the FDDs at any finite set of points may still define a valid Gaussian distribution. To resolve this issue, we seek to find a version $\tilde{W}$  of the process $W$ s.t. the sample paths $\tilde{W}$ possess the desired properties. For instance, if we need a space of continuous functions on $T$, we may apply the following theorem<br>
<img alt="GP_continuous" loading="lazy" src="/img_bayes_GP/GP_2.PNG"></p>
<p>A more abstract and general formulation of a Gaussian process is related to the dual space of a Banach space. Let  $\mathbb{B}$ be a Banach space. The dual space $\mathbb{B}^*$ is the space of continuous linear functionals on $\mathbb{B}$, i.e., the set of all linear maps from $\mathbb{B}$ to the scalar field.</p>
<dl>
<dt>Definition (Gaussian random element)</dt>
<dd><img alt="GP_def_2" loading="lazy" src="/img_bayes_GP/GP_3.PNG"></dd>
</dl>
<p>In this framework, the Gaussian Process can be viewed as a random element in the dual space $\mathbb{B}^*$∗, where the process is defined in terms of the behavior of random variables indexed by elements of a Banach space.</p>
<p>What is the relation between the above two definition of GP？With the second definition we can always construct a Gaussian stochastic process by $(b^{\*}(W):b^{\*}\in T)$, which are jointly normally distributed, for any subset $T\subset \mathbb{B}^*$. Additionally，if the sample paths $t\mapsto W_t$ of the stochastic process $W = (W_t:t\in T)$ belong to a Banach process $\mathbb{B}$ of functions $z:T\to \mathbb{R}$, then under some conditions the process will be a Gaussian random element. More specifically, the sample paths $t\mapsto W_t$ belonging to a Banach space means  that  the process must satisfy certain regularity conditions on the covariance structure and continuity of the sample paths.</p>
<h2 id="2-reproducing-kernel-hilbert-space">2. Reproducing Kernel Hilbert Space<a hidden class="anchor" aria-hidden="true" href="#2-reproducing-kernel-hilbert-space">#</a></h2>
<p>Every Gaussian process is naturally associated with a Hilbert space, determined by its covariance function. For a GP $W = (W_t: t\in T)$, let $\overline{lin}(W)$ be the closure of the set of all linear combinations $\sum_i \alpha_i W_{t_i}$ in the $L^2$-space of square-integrable variables. Then the space $\overline{lin}(W)$ is a Hilbert space, with inner product $< f,g> = E f\bar{g}$, called the first order chaos of $W$.</p>
<dl>
<dt>Definition (RKHS, 1)</dt>
<dd><img alt="RKHS_1" loading="lazy" src="/img_bayes_GP/GP_4.PNG"></dd>
</dl>
<p>It can be verified that $\mathbb{H}$ is a Hilbert space.</p>
<dl>
<dt>Lemma (Properties of RKHS)</dt>
<dd><img alt="RKHS_1_pty" loading="lazy" src="/img_bayes_GP/GP_5.PNG"></dd>
</dl>
<p>A Gaussian random element in a separable Banach space also comes with a RKHS. First we define the map $S:\mathbb{B}^*\to \mathbb{B}$ by</p>
$$Sb^* = E[b^*(W)W],$$<p>where the right side is the Pettis integral.</p>
<dl>
<dt>Definition (RKHS, 2)</dt>
<dd><img alt="RKHS_2" loading="lazy" src="/img_bayes_GP/GP_6.PNG"></dd>
</dl>
<p>The relationship between the two definitions is</p>
$$r(s,t) = E W_s W_t = E[\pi_s(W) \pi_t(W)] = \langle S\pi_s, S\pi_t \rangle_{\mathbb H},$$<p>
where $\pi_t: b\mapsto b(t)$ are elements in $\mathbb B^*$.</p>
<h2 id="3-small-ball-probability">3. Small Ball Probability<a hidden class="anchor" aria-hidden="true" href="#3-small-ball-probability">#</a></h2>
<p>As a Bayesian, we are always interested in the posterior consistency. Here we give some lemmas which are useful to study the posterior consistency of Gaussian process priors.</p>
<dl>
<dt>Lemma (Borell&rsquo;s)</dt>
<dd>Let $\Phi$ be the CDF of the standard normal.
<img alt="Borell&rsquo;s" loading="lazy" src="/img_bayes_GP/GP_7.PNG"></dd>
</dl>
<p>The additional small ball $\epsilon\mathbb B_1$ creates an $\epsilon$-cushion around $M\mathbb{B}_1$. This lemma suggests that if we want to use GP prior to estimate a function, we must ensure that the true function is contained in the closure of RKHS.</p>
<dl>
<dt>Lemma (Decentered)</dt>
<dd><img alt="Decentered" loading="lazy" src="/img_bayes_GP/GP_8.PNG"></dd>
<dt>Lemma (Small ball)</dt>
<dd><img alt="small ball" loading="lazy" src="/img_bayes_GP/GP_9.PNG"></dd>
</dl>
<h2 id="4-posterior-contraction">4. Posterior Contraction<a hidden class="anchor" aria-hidden="true" href="#4-posterior-contraction">#</a></h2>
<p>Before discussing the posterior contraction of GP priors, we need to introduce some theoretical concepts from infinite-dimensional Bayes theory. This will be a lengthy section, so I will dedicate a separate chapter to it. After that, we will return to discuss the case of GP priors.</p>
<h2 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h2>
<ul>
<li>
<p>[1] van der Vaart, A. W., &amp; van Zanten, J. H. (2008). Reproducing kernel Hilbert spaces of Gaussian priors.</p>
</li>
<li>
<p>[2] Ghosal, S., &amp; Van der Vaart, A. (2017). Fundamentals of nonparametric Bayesian inference.</p>
</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="prev" href="https://wangchxx.github.io/posts/bayes/bayes_6_gp2/">
    <span class="title">« Prev</span>
    <br>
    <span>Bayesian Statistics| Gaussian Process Priors (2)</span>
  </a>
  <a class="next" href="https://wangchxx.github.io/posts/bayes/bayes_5_contraction/">
    <span class="title">Next »</span>
    <br>
    <span>Bayesian Statistics| Posterior Consistency and Contraction</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="https://wangchxx.github.io/">My Notes</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
