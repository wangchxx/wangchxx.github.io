<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta property="og:url" content="https://wangchxx.github.io/posts/bayes/bayes_2_bvm/">
  <meta property="og:site_name" content="My Math Notes">
  <meta property="og:title" content="Bayesian Statistics| Bernstein-von Mises Theorem">
  <meta property="og:description" content="From a non-Bayesian perspective, when we aim to estimate the parameters of a certain model, we often apply the Central Limit Theorem (CLT) and obtain a result similar to this.
$$ \sqrt{n} (\hat{\theta}_n - \theta_0) \to N(0,\Sigma) $$From a Bayesian perspective, a similar conclusion can be drawn, often referred to as the Bayesian Central Limit Theorem. This is precisely the Bernstein-von Mises Theorem (BvM), which will be introduced in this article.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2021-07-18T10:52:59+02:00">
    <meta property="article:modified_time" content="2021-07-18T10:52:59+02:00">
    <meta property="article:tag" content="Markdown">
      <meta property="og:see_also" content="https://wangchxx.github.io/posts/bayes/bayes_7_gp3/">
      <meta property="og:see_also" content="https://wangchxx.github.io/posts/bayes/bayes_6_gp2/">
      <meta property="og:see_also" content="https://wangchxx.github.io/posts/bayes/bayes_4_gp1/">
      <meta property="og:see_also" content="https://wangchxx.github.io/posts/bayes/bayes_5_contraction/">
      <meta property="og:see_also" content="https://wangchxx.github.io/posts/bayes/bayes_3_dirichlet/">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Bayesian Statistics| Bernstein-von Mises Theorem">
  <meta name="twitter:description" content="From a non-Bayesian perspective, when we aim to estimate the parameters of a certain model, we often apply the Central Limit Theorem (CLT) and obtain a result similar to this.
$$ \sqrt{n} (\hat{\theta}_n - \theta_0) \to N(0,\Sigma) $$From a Bayesian perspective, a similar conclusion can be drawn, often referred to as the Bayesian Central Limit Theorem. This is precisely the Bernstein-von Mises Theorem (BvM), which will be introduced in this article.">

  
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#262d33">
  <title>
    
    My Math Notes - Bayesian Statistics| Bernstein-von Mises Theorem
    
  </title>
  
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@400;500;600;700&display=swap"
    rel="stylesheet">
  <link rel="stylesheet" href="https://unpkg.com/normalize.css">
  <link rel="stylesheet" type="text/css" media="screen" href="/css/main.css" />
  <link rel="stylesheet" type="text/css" media="screen" href="/css/md.css" />
  <link rel="stylesheet" type="text/css" media="screen" href="/css/syntax.css" />
  <script src="/js/main.js"></script>
</head>
<script>
  try {
    if (!('theme' in localStorage)) {
      localStorage.theme = window.matchMedia('(prefer-color-scheme: dark)').matches ? 'dark' : 'light';
    }
    document.querySelector('html').classList.add(localStorage.theme);
  } catch (e) {
    console.error(e);
  }
</script>
<body>
  <header>
  <h1 class="row gap-1">
    <div id="theme-switcher" class="btn lg-1"></div>
    My Math Notes
  </h1>
  <nav class="row gap-1">
  
    <a href="/">Home</a>
  
    <a href="/categories">Categories</a>
  
    <a href="/series">Series</a>
  
    <a href="/about">About</a>
  
  </nav>
  <hr>
</header>
  
  
<main>
	<h1>Bayesian Statistics| Bernstein-von Mises Theorem</h1>
	<div class="sm-1 mtb-1">
		Posted at &mdash; Jul 18, 2021
		
	</div>
	<p></p>
	<article class="md">
		<!-- raw HTML omitted -->
<p>From a non-Bayesian perspective, when we aim to estimate the parameters of a certain model, we often apply the Central Limit Theorem (CLT) and obtain a result similar to this.</p>
$$
\sqrt{n} (\hat{\theta}_n - \theta_0) \to N(0,\Sigma)
$$<p>From a Bayesian perspective, a similar conclusion can be drawn, often referred to as the Bayesian Central Limit Theorem. This is precisely the Bernstein-von Mises Theorem (BvM), which will be introduced in this article.</p>
<h2 id="0-notation">0. Notation</h2>
<hr>
<p>$I_\theta$: Fisher information,</p>
<p>$\ell_\theta(x) = \log p_\theta(x)$,</p>
<p>$\dot{\ell}_\theta(x) = \frac{d}{d \theta} \ell_\theta(x)$,</p>
<p>$\ddot{\ell}_\theta(x) = \frac{d^2}{d\theta^2} \ell_\theta(x)$,</p>
<p>$\Delta_{n,\theta} = 1/\sqrt{n} \sum_{i=1}^n \dot{\ell}_\theta(x_i)$,</p>
<p>$I_{n,\theta} = -1/n \sum_{i=1}^n \ddot{\ell}_\theta(x_i)$,</p>
<p>$||\cdot||_{TV}$: total variation,</p>
<hr>
<h2 id="1-preliminaries">1. Preliminaries</h2>
<ol>
<li>
<p>Bayes&rsquo; formula
By Bayes&rsquo; formula, the posterior density of  $\vartheta$ is given by
</p>
$$
    \begin{align*}
        \pi(\theta|X_1,...,X_n) = \frac{\prod_{i=1}^n p_\theta(X_i) \pi(\theta  )}{\int \prod_{i=1}^n p_\theta(X_i) \pi(\theta)d\theta}.
    \end{align*}
    $$</li>
<li>
<p>Taylor expansion
</p>
$$
  \log \frac{p_{\theta+h}}{p_\theta} (x) = h^T \dot{\ell}_\theta(x) + \frac{1}{2} h^T \ddot{\ell}_\theta(x) h + o_p(||h||^2).
  $$</li>
</ol>
<h2 id="2-bvm">2. BvM</h2>
<dl>
<dt>Theorem (BvM)</dt>
<dd>Under some conditions,
$$
\begin{equation}
        \Vert \Pi(\sqrt{n}(\vartheta - \theta_0)\in \cdot| X_1,...,X_n) - N_d(I_{\theta_0}^{-1}\Delta_{n,\theta_0}, I_{\theta_0}^{-1}) \Vert _{TV}\to 0 \; \text{ in } P_{\theta_0}^n.
\end{equation}
$$
Here the sequence of  variables  $\Delta_{n,\theta_0}$ converges under  $ \theta_0 $ in distribution to  $N_d(0, I_{\theta_0})$.</dd>
<dt>sketch pf proof</dt>
<dd>step 1: Taylor expansion to apply CLT,
<p><img src="/img_bayes_BvM/bvm_1.PNG" alt="taylor">
Notice that $\Delta_{n,\theta} \to \Delta_\theta:=N(0, I_\theta)$ in distribution, and $I_{n,\theta}\to I_{\theta}$ in probability  by CLT.</p>
<p>step 2: Rewrite the posterior.
In the first step, we observe that by performing a Taylor expansion on the log-likelihood, we can apply the CLT. Therefore, we aim to perform a Taylor expansion on the posterior distribution.
<img src="/img_bayes_BvM/bvm_2.PNG" alt="approx">
Now that we have rewritten the posterior into the form from step 1, we can perform a Taylor expansion on it. The numerator is approximately equal to: $h^T\Delta_{n,\theta} +  \frac{1}{2} h^T I_{\theta,n}h$.</p>
<p>step 3: Approximation posterior by Gaussian.
Additionally, for a Gaussian distribution, we can derive through calculation that
<img src="/img_bayes_BvM/bvm_3.PNG" alt="gaussian">
Let $\Delta_\theta = I_\theta X$, we can see that， $(P_{\theta+h/\sqrt{n}}) \to N(h,I_{\theta}^{-1})$， so the asymptotical behavior of the posterior can be represented in terms of $N(h,I_{\theta}^{-1})$ as
<img src="/img_bayes_BvM/bvm_4.PNG" alt="gaussian_asy">
where $X\sim I_{\theta_0}^{-1} N(0,I_{\theta_0})$.
$\Box$</p>
</dd>
</dl>
<h2 id="references">References</h2>
<ul>
<li>[1] Van der Vaart, A. W. (2000). Asymptotic statistics.</li>
<li>[2] Ghosal, S., &amp; Van der Vaart, A. (2017). Fundamentals of nonparametric Bayesian inference</li>
</ul>

	</article>
</main>
	
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: '\\[', right: '\\]', display: true},   
        {left: '$$', right: '$$', display: true},     
        {left: '$', right: '$', display: false},  
      ],
      throwOnError : false
    });
  });
</script>

	

	

	



  <footer class="row row-mob al-c-mob col-rev-mob sm-2-mob  jc-bt mtb-2">
  <p>
    © Copyright notice |
    <a href="https://github.com/mivinci/hugo-theme-minima" target="_blank" rel="noopener noreferrer">Minima</a> theme on
    <a href="https://gohugo.io" target="_blank" rel="noopener noreferrer">Hugo</a>
  </p>
  <p class="row gap-0_5">
    
      <a class="icon" href="https://github.com/wangchxx" title="github">
      
        <svg fill="#63636f" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
      
      </a>
    
  </p>
</footer>
</body>
</html>